{"cells":[{"cell_type":"markdown","metadata":{"id":"1gSnCTo2Dx7x"},"source":["# Network NPP"]},{"cell_type":"markdown","metadata":{"id":"vEJJ9IWJ3w8B"},"source":["# Part 1 Fetching the Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XohhpmjzDuGO"},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49700,"status":"ok","timestamp":1698058251648,"user":{"displayName":"Valerian Fourel","userId":"17150017961199078400"},"user_tz":-120},"id":"6YJIKWm03t6C","outputId":"749beafa-73e7-4585-f609-7f78c413d23a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DO83RxH43wD4"},"outputs":[],"source":["import numpy as np\n","import os\n","import torch\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import dask.dataframe as dd\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils.data\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import random\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9WYBK7QhIYFz"},"outputs":[],"source":["import zipfile\n","\n","# Replace the zip_file_path with the path to the zip file in your Google Drive\n","\n","zip_file_pathMODIS2015 = '/content/drive/MyDrive/dataNPPTensor.zip'\n","zip_file_paths = [zip_file_pathMODIS2015]\n","\n","# Replace the destination_folder with the path of the folder where you want to extract the contents\n","\n","destination_folderMODIS = '/content/dataNPP'\n","destination_folders = [destination_folderMODIS]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3NbOYJIS4cWw"},"outputs":[],"source":["# Unzip the file\n","\n","for i in range(len(destination_folders)):\n","  with zipfile.ZipFile(zip_file_paths[i], 'r') as zip_ref:\n","      zip_ref.extractall(destination_folders[i])\n"]},{"cell_type":"markdown","metadata":{"id":"yytloi1zIxXa"},"source":["# Part 2 Custom Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WBqYGaia4W0Z"},"outputs":[],"source":["\n","sampleCoordinatesNppIDArrayPositionDf_file = '/content/drive/MyDrive/sampleCoordinatesNppIDArrayPositionDf.parquet'\n","sampleCoordinatesNppIDArrayPositionDf = dd.read_parquet(sampleCoordinatesNppIDArrayPositionDf_file).compute()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"srIybyIEIrXz"},"outputs":[],"source":["\n","class CustomRasterDataset(torch.utils.data.Dataset):\n","    'Characterizes a dataset for PyTorch'\n","    def __init__(self, dataFrame, file_path, file_extension,windowSize,re_scale = False,new_min = -1,new_max = 1):\n","        'Initialization'\n","        self.re_scale = re_scale\n","        self.new_min  = new_min\n","        self.new_max = new_max\n","        self.dataFrame = dataFrame\n","        self.file_path = file_path\n","        self.file_extension = file_extension\n","        self.windowSize = windowSize\n","        self.offset = self.windowSize // 2\n","\n","\n","    def __len__(self):\n","        'Denotes the total number of samples'\n","        return len(self.dataFrame)\n","\n","    def __getitem__(self, index):\n","        'Generates one sample of data'\n","        # Select sample\n","        ID =  self.dataFrame.iloc[index]['ID'] # str(ID).rstrip('.0')\n","\n","\n","        x = self.dataFrame.iloc[index]['x'] + random.choice([-2, -1, 0, 1, 2])\n","        y = self.dataFrame.iloc[index]['y'] + random.choice([-2, -1, 0, 1, 2])\n","        # Load data and get label\n","        fullArray = torch.load(self.file_path+ID+self.file_extension)\n","        # Determine the window for the square\n","        left = x - self.offset\n","        right = x + (self.offset + 1)\n","        top = y - self.offset\n","        bottom = y + (self.offset + 1)\n","        X = fullArray[left:right,top:bottom].clone().detach()  # Access value in gpu_dictElevation\n","        # if self.re_scale:\n","          # X =  re_scale(X,self.new_min,self.new_max)\n","        return X.unsqueeze(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TFSBZI-Z1abE"},"outputs":[],"source":["import torch.nn.functional as F\n","\n","def normalize_tensor01(tensor):\n","    max_val = torch.max(tensor)\n","    min_val = torch.min(tensor)\n","\n","    # Avoid division by zero\n","    if max_val - min_val != 0:\n","        normalized_tensor = (tensor - min_val) / (max_val - min_val)\n","    else:\n","        normalized_tensor = tensor - min_val\n","\n","    return normalized_tensor\n","\n","def normalized_mse(tensor1, tensor2):\n","    # Normalize the tensors\n","    norm_tensor1 = normalize_tensor01(tensor1)\n","    norm_tensor2 = normalize_tensor01(tensor2)\n","\n","    # Compute MSE\n","    mse_loss_normalized = F.mse_loss(norm_tensor1, norm_tensor2)\n","    mse_loss =  F.mse_loss(tensor1, tensor2)\n","\n","    return mse_loss_normalized, mse_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ECfBeIIC4xYK"},"outputs":[],"source":["file_pathNPP = '/content/dataNPP/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lazuZM805cMJ"},"outputs":[],"source":["file_extension = '.pt'\n","num_workers = 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4MJ1NKm15e3S"},"outputs":[],"source":["batch_sizeNPP = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NA2WSa795EBB"},"outputs":[],"source":["windowSizeNPP = 33\n","datasetNPP = CustomRasterDataset(sampleCoordinatesNppIDArrayPositionDf, '/content/dataNPP/', file_extension,windowSizeNPP)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2D59gWs_5Fme"},"outputs":[],"source":["dataLoaderNPP = DataLoader(datasetNPP, batch_size=batch_sizeNPP, num_workers=num_workers, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":358,"status":"ok","timestamp":1698058264988,"user":{"displayName":"Valerian Fourel","userId":"17150017961199078400"},"user_tz":-120},"id":"2yuJWOnUinOY","outputId":"c7054240-ff0d-47e9-c107-957b49dc2fb1"},"outputs":[{"output_type":"stream","name":"stdout","text":["First Batch:\n","torch.Size([32, 1, 33, 33])\n"]}],"source":["# Assuming you have already created the 'elevation_dataloader' as mentioned in the previous steps\n","\n","# Get the first batch from the dataloader using the 'next' function\n","first_batch = next(iter(dataLoaderNPP))\n","second_batch = next(iter(dataLoaderNPP))\n","# Print the content of the first batch\n","print(\"First Batch:\")\n","print(first_batch.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"aRUJZEj2M_yz"},"source":["# Part 3. Architecture of the NPP VAE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1698058264988,"user":{"displayName":"Valerian Fourel","userId":"17150017961199078400"},"user_tz":-120},"id":"_uwMWxnLDFSt","outputId":"c7cd30ba-cc36-46fa-b7aa-20e844239386"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["29555.59375"]},"metadata":{},"execution_count":15}],"source":["loss_weight = len(sampleCoordinatesNppIDArrayPositionDf)/batch_sizeNPP\n","loss_weight"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZUZm6kj6_oH7"},"outputs":[],"source":["def re_scale(data, new_min=0, new_max=1):\n","    # Calculate mean and center the data around zero\n","    mean = data.mean()\n","    min_value = data.min()\n","    max_value = data.max()\n","    centered_data = data - mean\n","\n","    scaled_data = (centered_data - min_value) / (max_value - min_value)  # Scale between 0 and 1\n","    scaled_data = scaled_data * (new_max - new_min) + new_min  # Scale to new range\n","\n","\n","    return scaled_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wLadbFFfAGzk"},"outputs":[],"source":["# Define the MSE loss function\n","loss_fn = nn.MSELoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-pXvVuWXAxuz"},"outputs":[],"source":["%%capture\n","!pip install torchmetrics\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VvCzA-uONiQk"},"outputs":[],"source":["\n","class NPPVAELoss(nn.Module):\n","    def __init__(self):\n","        super(NPPVAELoss, self).__init__()\n","\n","    def forward(self, reconstructed_x, x, mu, logvar):\n","        # Compute the Mean Squared Error (MSE) reconstruction loss\n","        # loss = nn.MSELoss(reduction='sum')(reconstructed_x, x)\n","        loss_value_l1 = nn.MSELoss(reduction='mean')(reconstructed_x,x)\n","        reconstructed_x_repeated =  normalize_tensor01(reconstructed_x).repeat(1, 3, 1, 1)\n","        x_repeated = normalize_tensor01(x).repeat(1, 3, 1, 1)\n","\n","        # Compute the Mean Squared Error (MSE) reconstruction loss\n","        lpips_loss = lpips(reconstructed_x_repeated, x_repeated)\n","        # Compute the KL divergence term\n","        kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n","        # Return the sum of the reconstruction loss and KL divergence term\n","\n","        return kl_divergence , lpips_loss*loss_weight , loss_value_l1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NvY30xAdNC6r"},"outputs":[],"source":["\n","class ResDown(nn.Module):\n","    \"\"\"\n","    Residual down sampling block for the encoder\n","    \"\"\"\n","\n","    def __init__(self, channel_in, channel_out, kernel_size=3):\n","        super(ResDown, self).__init__()\n","        self.conv1 = nn.Conv2d(channel_in, channel_out // 2, kernel_size, 2, kernel_size // 2)\n","        self.bn1 = nn.BatchNorm2d(channel_out // 2, eps=1e-4)\n","        self.conv2 = nn.Conv2d(channel_out // 2, channel_out, kernel_size, 1, kernel_size // 2)\n","        self.bn2 = nn.BatchNorm2d(channel_out, eps=1e-4)\n","\n","        self.conv3 = nn.Conv2d(channel_in, channel_out, kernel_size, 2, kernel_size // 2)\n","\n","        self.act_fnc = nn.ELU()\n","\n","    def forward(self, x):\n","        skip = self.conv3(x)\n","        x = self.act_fnc(self.bn1(self.conv1(x)))\n","        x = self.conv2(x)\n","        return self.act_fnc(self.bn2(x + skip))\n","\n","\n","class ResUp(nn.Module):\n","    \"\"\"\n","    Residual up sampling block for the decoder\n","    \"\"\"\n","\n","    def __init__(self, channel_in, channel_out, kernel_size=3, scale_factor=2):\n","        super(ResUp, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(channel_in, channel_in // 2, kernel_size, 1, kernel_size // 2)\n","        self.bn1 = nn.BatchNorm2d(channel_in // 2, eps=1e-4)\n","        self.conv2 = nn.Conv2d(channel_in // 2, channel_out, kernel_size, 1, kernel_size // 2)\n","        self.bn2 = nn.BatchNorm2d(channel_out, eps=1e-4)\n","\n","        self.conv3 = nn.Conv2d(channel_in, channel_out, kernel_size, 1, kernel_size // 2)\n","\n","        self.up_nn = nn.Upsample(scale_factor=scale_factor, mode=\"nearest\")\n","\n","        self.act_fnc = nn.ELU()\n","\n","    def forward(self, x):\n","        x = self.up_nn(x)\n","        skip = self.conv3(x)\n","        x = self.act_fnc(self.bn1(self.conv1(x)))\n","        x = self.conv2(x)\n","\n","        return self.act_fnc(self.bn2(x + skip))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J7HEqAt_7_27"},"outputs":[],"source":["\n","# Define the encoder network\n","class NppEncoder(nn.Module):\n","    def __init__(self, latent_dim):\n","        super(NppEncoder, self).__init__()\n","        self.latent_dim = latent_dim\n","        self.conv_in = nn.Conv2d(1, 4, 5, 1, 3)\n","        self.res_down_block1 = ResDown(4, 8)\n","        self.res_down_block2 = ResDown(8, 16)\n","        self.res_down_block3 = ResDown(16,32)\n","        self.res_down_block4 = ResDown(32, 64)\n","        self.conv_mu = nn.Conv2d(64, latent_dim, 3, 1)\n","        self.conv_log_var = nn.Conv2d(64, latent_dim, 3, 1)\n","        self.act_fnc = nn.ELU()\n","\n","\n","    def forward(self, x):\n","        x = self.act_fnc(self.conv_in(x))\n","        x = self.res_down_block1(x)  # 32\n","        x = self.res_down_block2(x)  # 16\n","        x = self.res_down_block3(x)  # 8\n","        x = self.res_down_block4(x)  # 8\n","        mu = self.conv_mu(x)  # 1\n","        logvar = self.conv_log_var(x)  # 1\n","\n","        return mu, logvar\n","\n","# Define the decoder network\n","class NppDecoder(nn.Module):\n","    def __init__(self, latent_dim):\n","        super(NppDecoder, self).__init__()\n","        self.latent_dim = latent_dim\n","        self.conv_t_up = nn.ConvTranspose2d(latent_dim, 128, 4, 2)\n","        self.res_up_block1 = ResUp(128, 64)\n","        self.res_up_block2 = ResUp(64, 32)\n","        self.res_up_block3 = ResUp(32,16)\n","        self.res_up_block4 = ResUp(16,10)\n","        self.res_up_block5 = ResUp(10,8)\n","        self.res_down_block1 = ResDown(8,16)\n","        self.res_down_block2 = ResDown(16,32)\n","\n","\n","        self.conv_out1 = nn.Conv2d(32, 1, 4, stride=1, padding=2)\n","\n","\n","        self.act_fnc = nn.ELU()\n","        self.act_fnc2 = nn.ELU()\n","\n","\n","    def forward(self, x):\n","        x = x.view(x.shape[0], self.latent_dim, 1, 1)\n","        x = self.act_fnc(self.conv_t_up(x))  # 4\n","        x = self.res_up_block1(x)  # 8\n","        x = self.res_up_block2(x)  # 16\n","        x = self.res_up_block3(x)  # 32\n","        x = self.res_up_block4(x)  # 32\n","        x = self.res_up_block5(x)  # 32\n","        x = self.res_down_block1(x)\n","        x = self.res_down_block2(x)\n","\n","\n","        x = self.conv_out1(x)\n","\n","        return x\n","\n","# Combine the encoder and decoder to form the VAE\n","class NppVAE(nn.Module):\n","    def __init__(self, latent_dim):\n","        super(NppVAE, self).__init__()\n","        self.latent_dim = latent_dim\n","        self.encoder = NppEncoder(latent_dim)\n","        self.decoder = NppDecoder(latent_dim)\n","\n","    def encode(self, x):\n","        return self.encoder(x)\n","\n","    def decode(self, z):\n","        return self.decoder(z)\n","\n","    def reparameterize(self, mu, logvar):\n","        std = torch.exp(0.5 * logvar)\n","        eps = torch.randn_like(std)\n","        z = mu + eps * std\n","        return z\n","\n","    def forward(self, x):\n","        mu, logvar = self.encode(x)\n","        z = self.reparameterize(mu, logvar)\n","        reconstructed_x = self.decode(z)\n","        return reconstructed_x, mu, logvar\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1029,"status":"ok","timestamp":1698058275368,"user":{"displayName":"Valerian Fourel","userId":"17150017961199078400"},"user_tz":-120},"id":"UZzKFJTQig90","outputId":"d5bab633-0437-43f1-ea97-da9fd8f97abb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reconstructed batch shape: torch.Size([32, 1, 33, 33])\n"]}],"source":["\n","# Instantiate the VAE with the desired latent_dim\n","latent_dim = 40\n","vae = NppVAE(latent_dim)\n","\n","# Pass the input batch through the VAE\n","reconstructed_batch, mu, logvar = vae(first_batch)\n","\n","# Check the output shape\n","print(\"Reconstructed batch shape:\", reconstructed_batch.shape)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UEhQ0Bkn1VjN"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"8OiPF6yW6X7Z"},"source":["# Part 4 Training the VAE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AynZH0k61V_U"},"outputs":[],"source":["\n","\n","\n","# Compute average normalized MSE for the first 100 batches\n","def compute_average_mse(dataloader,vae):\n","    mse_values = []\n","    count = 0\n","\n","    for data in dataloader:\n","        if count >= 10000:\n","            break\n","\n","        # Generate random \"predictions\" just for the sake of the example\n","        # In a real scenario, these would be the model's output\n","        reconstructed_batch, _, _ = vae(data.to(device))\n","\n","        mse,mse2 = normalized_mse(data.cpu(), reconstructed_batch.cpu())\n","        mse_values.append(mse.item())\n","\n","        count += 1\n","\n","    average_mse = sum(mse_values) / len(mse_values)\n","    print(\"Average Normalized MSE:\", average_mse)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F9lPMUUn7tqj"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4MmYOt_t7wQ0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iWBTNc-v7x8z"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AaBPYlPN7zkb"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C0dLmuf06xqi"},"outputs":[],"source":["learning_rateNPP = 0.001\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WWGTdjH-6zmj"},"outputs":[],"source":["latent_dimNPP = 40"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11634,"status":"ok","timestamp":1698058286997,"user":{"displayName":"Valerian Fourel","userId":"17150017961199078400"},"user_tz":-120},"id":"kjpXI9cnDBLx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"58bff51b-c72e-4af2-eb30-0adba83b2daf"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/squeezenet1_1-b8a52dc0.pth\" to /root/.cache/torch/hub/checkpoints/squeezenet1_1-b8a52dc0.pth\n","100%|██████████| 4.73M/4.73M [00:00<00:00, 22.0MB/s]\n"]}],"source":["from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity\n","lpips = LearnedPerceptualImagePatchSimilarity(net_type='squeeze').to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EXzlWkA57g5D"},"outputs":[],"source":["def re_scale(data, new_min=0, new_max=1):\n","    # Calculate mean and center the data around zero\n","    mean = data.mean()\n","    min_value = data.min()\n","    max_value = data.max()\n","    centered_data = data - mean\n","\n","    scaled_data = (centered_data - min_value) / (max_value - min_value)  # Scale between 0 and 1\n","    scaled_data = scaled_data * (new_max - new_min) + new_min  # Scale to new range\n","\n","\n","    return scaled_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qjw7dIZv6ePL"},"outputs":[],"source":["\n","# Define the function to train the VAE\n","def train_vae(vae, dataloader, num_epochs, learning_rate):\n","    # Set the model to training mode\n","    vae.train()\n","\n","    # Define the Mean Squared Error (MSE) loss function\n","    criterion = NPPVAELoss()\n","    mse = torch.nn.MSELoss()\n","\n","    # Define the optimizer (you can experiment with different optimizers)\n","    optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n","    total_batches = len(dataloader)\n","    batches_done = 0\n","    lpips = LearnedPerceptualImagePatchSimilarity(net_type='squeeze').to(device)\n","\n","    for epoch in range(num_epochs):\n","        total_loss = 0.0\n","        batches_done =0\n","        mse_loss = 0\n","        for batch_idx, data in enumerate(dataloader):\n","            # Get the batch of data and move it to the device (e.g., GPU if available)\n","            # inputs = data\n","            dimensions = data.shape\n","\n","            inputs = data.to(device)\n","\n","            # Zero the gradients\n","            optimizer.zero_grad()\n","            # Forward pass\n","            x_final, mu, logvar = vae(inputs)\n","            # Compute the MSE loss\n","            kl_divergence , lpips_loss , l1_loss = criterion(x_final,  inputs,mu, logvar)\n","            loss =  kl_divergence + (lpips_loss*0.2*loss_weight + l1_loss*0.5)\n","            # Backward pass\n","            loss.backward()\n","\n","            # Update the parameters\n","            optimizer.step()\n","\n","            # Update the total loss for the epoch\n","            total_loss += loss.item()\n","\n","            # Update the number of batches processed\n","            batches_done += 1\n","            mse_loss += mse(normalize_tensor01(x_final),normalize_tensor01(inputs))\n","\n","            # Print the progress when a tenth of the epoch is completed\n","            if batches_done % (len(dataloader) // 10) == 0:\n","                print(f\"Epoch [{epoch+1}/{num_epochs}] - Progress: {batches_done}/{len(dataloader)} - Total Loss: {total_loss / (len(dataloader) // 10)},  {mse_loss.item()/ (len(dataloader) // 10)}\")\n","                total_loss = 0\n","                mse_loss = 0\n","\n","        # Print the average loss for the epoch\n","        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {total_loss / (len(dataloader)  % 10)}\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aKaQzvZO6mxS"},"outputs":[],"source":["# Example usage:'device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")'\n","# Assuming you have the training data in 'train_dataloader' and a device set, e.g.,\n","# Instantiate the VAE with the desired latent_dim\n","vae = NppVAE(latent_dimNPP).to(device)\n","\n","# Define the number of epochs and learning rate\n","num_epochs = 3\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":396,"status":"ok","timestamp":1698058287370,"user":{"displayName":"Valerian Fourel","userId":"17150017961199078400"},"user_tz":-120},"id":"S4Q1uvjAwtXE","outputId":"d3970a24-8e13-44c2-9354-561c95e6088a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["453006"]},"metadata":{},"execution_count":31}],"source":["def count_parameters(model):\n","    \"\"\"\n","    Count the number of parameters in a PyTorch model.\n","\n","    Args:\n","        model (torch.nn.Module): The neural network model.\n","\n","    Returns:\n","        int: Total number of parameters in the model.\n","    \"\"\"\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","# Example usage:\n","# model = YourNeuralNetworkClassHere(...)\n","# print(count_parameters(model))\n","count_parameters(vae)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"54X30SFU7-ST","outputId":"a6ca2af3-376a-495a-b200-5185eddf09cb","executionInfo":{"status":"error","timestamp":1698060675271,"user_tz":-120,"elapsed":1780628,"user":{"displayName":"Valerian Fourel","userId":"17150017961199078400"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/3] - Progress: 2955/29556 - Total Loss: 29763437.718443315,  0.014166764519137981\n","Epoch [1/3] - Progress: 5910/29556 - Total Loss: 27084966.442639593,  0.009104313342099263\n","Epoch [1/3] - Progress: 8865/29556 - Total Loss: 26092821.3678511,  0.007750701258832025\n","Epoch [1/3] - Progress: 11820/29556 - Total Loss: 25505770.854145516,  0.007098683003846764\n","Epoch [1/3] - Progress: 14775/29556 - Total Loss: 25136173.397631135,  0.006690518142003094\n","Epoch [1/3] - Progress: 17730/29556 - Total Loss: 24421214.785109982,  0.0064748825357246725\n","Epoch [1/3] - Progress: 20685/29556 - Total Loss: 20511023.584771574,  0.006425823979773094\n","Epoch [1/3] - Progress: 23640/29556 - Total Loss: 8946872.901861252,  0.006763298822135086\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-dab5a9415d56>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the VAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataLoaderNPP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rateNPP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-29-a11875f564a0>\u001b[0m in \u001b[0;36mtrain_vae\u001b[0;34m(vae, dataloader, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mx_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;31m# Compute the MSE loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mkl_divergence\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlpips_loss\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0ml1_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_final\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-a50d4a19af8b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mreconstructed_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreconstructed_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-a50d4a19af8b>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-a50d4a19af8b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_up_block1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_up_block2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_up_block3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_up_block4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_up_block5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-5df5c69886f7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mskip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fnc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Train the VAE\n","train_vae(vae, dataLoaderNPP, num_epochs, learning_rateNPP)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZAfbOjN240Uy"},"outputs":[],"source":["torch.save(vae, 'vaeNPP3Epoch2.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zTDMnICi42o7"},"outputs":[],"source":["!mv vaeNPP3Epoch2.pt \"/content/drive/MyDrive/Colab Notebooks/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WXYQo2qW5ZZD"},"outputs":[],"source":["# Example usage\n","# Replace `your_dataloader` with the DataLoader you have\n","compute_average_mse(dataLoaderNPP,vae)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ELvoDUJ6PFS_"},"outputs":[],"source":["train_vae(vae, dataLoaderNPP, 2, learning_rateNPP)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FE9hfrCYO-Fe"},"outputs":[],"source":["torch.save(vae, 'vaeNPP5Epoch2.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ctFZqSdDPAJ-"},"outputs":[],"source":["!mv vaeNPP5Epoch2.pt \"/content/drive/MyDrive/Colab Notebooks/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P8CmOaCI5cYP"},"outputs":[],"source":["# Example usage\n","# Replace `your_dataloader` with the DataLoader you have\n","compute_average_mse(dataLoaderNPP,vae)"]},{"cell_type":"markdown","metadata":{"id":"dYV1vzs2MJ4S"},"source":["# Part 5. Plotting the results of the NPP VAE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i6Df5689MNkq"},"outputs":[],"source":["def get_random_batch(dataloader):\n","    # Get the total number of batches in the DataLoader\n","    num_batches = len(dataloader)\n","\n","    # Generate a random index to select a batch\n","    random_batch_index = torch.randint(0, 100, (1,))\n","\n","    # Iterate through the DataLoader to find the batch at the random index\n","    for i, batch in enumerate(dataloader):\n","        if i == random_batch_index:\n","            return batch\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YUdKjsZ4LG7t"},"outputs":[],"source":["randomBatch = get_random_batch(dataLoaderNPP)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7HmLGEqALJ19"},"outputs":[],"source":["\n","def compare_vae_reconstruction(vae, data_batch, device):\n","    # Set the VAE to evaluation mode\n","    vae.eval()\n","\n","    # Get the batch size and number of channels\n","    batch_size, num_channels, height, width = data_batch.size()\n","\n","    # Get the reconstructed images from the VAE\n","    with torch.no_grad():\n","\n","        inputs = data_batch\n","\n","        reconstructed_batch, _, _ = vae(inputs.to(device))\n","\n","    # Convert the tensors to numpy arrays and transpose the dimensions\n","    original_images = data_batch.cpu().numpy().transpose(0, 2, 3, 1)\n","    reconstructed_images = reconstructed_batch.cpu().numpy().transpose(0, 2, 3, 1)\n","    # Plot the original and reconstructed images side by side\n","    plt.figure(figsize=(100, 100))\n","\n","    for i in range(batch_size):\n","        plt.subplot(batch_size, 16, i*16 + 1)\n","        plt.imshow(original_images[i])\n","        plt.axis('off')\n","        plt.title('Original')\n","\n","        plt.subplot(batch_size, 16, i*16 + 2)\n","        plt.imshow(reconstructed_images[i])\n","        plt.axis('off')\n","        plt.title('Reconstructed')\n","\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Usage\n","# Assuming 'vae' is your trained Variational Autoencoder model\n","# and 'data_batch' is your batch of input images\n","# 'device' should be the device on which your model is (e.g., 'cuda' or 'cpu')\n","compare_vae_reconstruction(vae, randomBatch, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SP98Bgr9LmGW"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ISx3Uci0LVIN"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyN0DJMKPb870drgUT5aJ9I0"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}