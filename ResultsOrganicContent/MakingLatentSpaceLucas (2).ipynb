{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a3dta0aRprp",
        "outputId": "058a80da-d454-432a-83c5-88cbb82e4935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_7BHmvra-qo"
      },
      "source": [
        "# Part 1: Get the LUCAS Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3TP6lEX1WL1I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6d21147-a14d-4749-f2b6-b55ed7ab5a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import dask.dataframe as dd\n",
        "import glob\n",
        "import pandas as pd\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6wRPofoAWB5l"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the folder path\n",
        "folder_path = '/content/drive/MyDrive/MLTRANS/FilteredLucas/'\n",
        "\n",
        "# List Excel files in the folder\n",
        "excel_files = glob.glob(folder_path + '*.xlsx')\n",
        "\n",
        "# Create a list of tuples with (file name, Dask DataFrame) pairs\n",
        "dfs = [(file,dd.from_pandas(pd.read_excel(file), npartitions=1)) for file in excel_files]\n",
        "\n",
        "# You now have a list of tuples where each tuple contains the file name and its associated Dask DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5cttKXvRWXQN"
      },
      "outputs": [],
      "source": [
        "fileNpp, NppDf = dfs[0]\n",
        "fileLst, LstDf = dfs[1]\n",
        "fileLAI, LAIDf = dfs[2]\n",
        "fileEvapo, EvapoDf = dfs[3]\n",
        "fileElevation, ElevationDf = dfs[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "fFZhSW0QlkEx",
        "outputId": "6edc93d8-4dd0-48e4-b028-4fe8b38cf715"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dask DataFrame Structure:\n",
              "                  id      x      y     survey_date point_ids       OC\n",
              "npartitions=1                                                        \n",
              "0              int64  int64  int64  datetime64[ns]     int64  float64\n",
              "16728            ...    ...    ...             ...       ...      ...\n",
              "Dask Name: from_pandas, 1 graph layer"
            ],
            "text/html": [
              "<div><strong>Dask DataFrame Structure:</strong></div>\n",
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>survey_date</th>\n",
              "      <th>point_ids</th>\n",
              "      <th>OC</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>npartitions=1</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>int64</td>\n",
              "      <td>int64</td>\n",
              "      <td>int64</td>\n",
              "      <td>datetime64[ns]</td>\n",
              "      <td>int64</td>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16728</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "<div>Dask Name: from_pandas, 1 graph layer</div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "NppDf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UEyh26_q5uB2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0Z7xS2TbDJr"
      },
      "source": [
        "# Part 2: Get the VAEs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kv1XWC1_cHAs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import dask.dataframe as dd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "import torch.optim as optim\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3JT6HJ90cAbM"
      },
      "outputs": [],
      "source": [
        "class ResDown(nn.Module):\n",
        "    \"\"\"\n",
        "    Residual down sampling block for the encoder\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channel_in, channel_out, kernel_size=3):\n",
        "        super(ResDown, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(channel_in, channel_out // 2, kernel_size, 2, kernel_size // 2)\n",
        "        self.bn1 = nn.BatchNorm2d(channel_out // 2, eps=1e-4)\n",
        "        self.conv2 = nn.Conv2d(channel_out // 2, channel_out, kernel_size, 1, kernel_size // 2)\n",
        "        self.bn2 = nn.BatchNorm2d(channel_out, eps=1e-4)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(channel_in, channel_out, kernel_size, 2, kernel_size // 2)\n",
        "\n",
        "        self.act_fnc = nn.ELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip = self.conv3(x)\n",
        "        x = self.act_fnc(self.bn1(self.conv1(x)))\n",
        "        x = self.conv2(x)\n",
        "        return self.act_fnc(self.bn2(x + skip))\n",
        "\n",
        "\n",
        "class ResUp(nn.Module):\n",
        "    \"\"\"\n",
        "    Residual up sampling block for the decoder\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channel_in, channel_out, kernel_size=3, scale_factor=2):\n",
        "        super(ResUp, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(channel_in, channel_in // 2, kernel_size, 1, kernel_size // 2)\n",
        "        self.bn1 = nn.BatchNorm2d(channel_in // 2, eps=1e-4)\n",
        "        self.conv2 = nn.Conv2d(channel_in // 2, channel_out, kernel_size, 1, kernel_size // 2)\n",
        "        self.bn2 = nn.BatchNorm2d(channel_out, eps=1e-4)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(channel_in, channel_out, kernel_size, 1, kernel_size // 2)\n",
        "\n",
        "        self.up_nn = nn.Upsample(scale_factor=scale_factor, mode=\"nearest\")\n",
        "\n",
        "        self.act_fnc = nn.ELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.up_nn(x)\n",
        "        skip = self.conv3(x)\n",
        "        x = self.act_fnc(self.bn1(self.conv1(x)))\n",
        "        x = self.conv2(x)\n",
        "\n",
        "        return self.act_fnc(self.bn2(x + skip))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "y7w2kamIcO-R"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the encoder network\n",
        "class EvapoEncoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(EvapoEncoder, self).__init__()\n",
        "        self.conv_in = nn.Conv2d(1, 8, 7, 1, padding=1)\n",
        "        # self.dropout = nn.Dropout(p=0.3)\n",
        "        self.res_down_block1 = ResDown(8, 16)\n",
        "        self.res_down_block2 = ResDown(16, 32)\n",
        "        self.res_down_block3 = ResDown(32,64)\n",
        "        self.res_down_block4 = ResDown(64, 256)\n",
        "\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.conv_mu = nn.Linear(1024, latent_dim,)\n",
        "        self.conv_log_var = nn.Linear(1024, latent_dim)\n",
        "        self.act_fnc = nn.ELU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act_fnc(self.conv_in(x))\n",
        "        # x = self.dropout(x)\n",
        "        x = self.res_down_block1(x)  # 32\n",
        "        x = self.res_down_block2(x)  # 16\n",
        "        x = self.res_down_block3(x)  # 8\n",
        "        x = self.res_down_block4(x)  # 8\n",
        "\n",
        "        x =  self.flatten(x)\n",
        "        mu = self.conv_mu(x)  # 1\n",
        "        logvar = self.conv_log_var(x)  # 1\n",
        "\n",
        "        return mu, logvar\n",
        "\n",
        "# Define the decoder network\n",
        "class EvapoDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(EvapoDecoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        # self.linear = nn.Linear(self.latent_dim,self.latent_dim)\n",
        "        # self.act_fnc1 = nn.ELU()\n",
        "        self.conv_t_up = nn.ConvTranspose2d(latent_dim, 128, 4, 2,padding=0)\n",
        "        self.act_fnc2 = nn.ELU()\n",
        "        self.act_fnc = nn.ELU()\n",
        "\n",
        "                # Adding dropout layer\n",
        "        # self.dropout = nn.Dropout(p=0.3)\n",
        "        self.res_up_block1 = ResUp(128, 64)\n",
        "        self.res_up_block2 = ResUp(64, 32)\n",
        "        self.res_up_block3 = ResUp(32,16)\n",
        "        self.res_up_block4 = ResUp(16,8)\n",
        "        self.res_up_block5 = ResUp(8,4)\n",
        "        self.res_down_block1 = ResDown(4, 16)\n",
        "        self.res_down_block2 = ResDown(16, 32)\n",
        "\n",
        "\n",
        "        self.conv_out1 = nn.Conv2d(32, 1, 4, stride=1, padding=2)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.act_fnc1(self.linear(x))\n",
        "        x = x.view(x.shape[0], self.latent_dim, 1, 1)  # Reshape into a 5x5 tensor\n",
        "        x = self.act_fnc2(self.conv_t_up(x))  # 4\n",
        "        # x = self.dropout(x)\n",
        "        x = self.res_up_block1(x)  # 8\n",
        "        x = self.res_up_block2(x)  # 16\n",
        "        x = self.res_up_block3(x)  # 32\n",
        "        x = self.res_up_block4(x)  # 32\n",
        "        x =  self.res_up_block5(x)\n",
        "        x = self.res_down_block1(x)  # 32\n",
        "        x = self.res_down_block2(x)  # 16\n",
        "        x = self.conv_out1(x)\n",
        "\n",
        "        return  x\n",
        "\n",
        "# Combine the encoder and decoder to form the VAE\n",
        "class EvapoVAE(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(EvapoVAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = EvapoEncoder(self.latent_dim)\n",
        "        self.decoder = EvapoDecoder(self.latent_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = mu + eps * std\n",
        "        return z\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstructed_x = self.decode(z)\n",
        "        return reconstructed_x, mu, logvar\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZWJP1wz0cSYe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the encoder network\n",
        "class ElevationEncoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(ElevationEncoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.conv_in = nn.Conv2d(1, 4, 7, 1, 3)\n",
        "        self.res_down_block1 = ResDown(4, 8)\n",
        "        self.res_down_block2 = ResDown(8, 16)\n",
        "        self.res_down_block3 = ResDown(16,32)\n",
        "        self.res_down_block4 = ResDown(32, 64)\n",
        "        self.conv_mu = nn.Conv2d(64, latent_dim, 5, 1)\n",
        "        self.conv_log_var = nn.Conv2d(64, latent_dim, 5, 1)\n",
        "        self.act_fnc = nn.ELU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act_fnc(self.conv_in(x))\n",
        "        x = self.res_down_block1(x)  # 32\n",
        "        x = self.res_down_block2(x)  # 16\n",
        "        x = self.res_down_block3(x)  # 8\n",
        "        x = self.res_down_block4(x)\n",
        "        mu = self.conv_mu(x)  # 1\n",
        "        logvar = self.conv_log_var(x)  # 1\n",
        "\n",
        "        return mu, logvar\n",
        "\n",
        "# Define the decoder network\n",
        "class ElevationDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(ElevationDecoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.conv_t_up = nn.ConvTranspose2d(latent_dim, 128, 4, 1)\n",
        "        self.res_up_block1 = ResUp(128, 32)\n",
        "        self.res_up_block2 = ResUp(32, 16)\n",
        "        self.res_up_block3 = ResUp(16,8)\n",
        "        self.res_up_block4 = ResUp(8,4)\n",
        "        self.res_up_block5 = ResUp(4,2)\n",
        "\n",
        "        self.res_down_block1 = ResDown(2,16)\n",
        "\n",
        "\n",
        "        self.conv_out1 = nn.Conv2d(16, 1, 2, stride=1, padding=1)\n",
        "        # self.conv_out3 = nn.Conv2d(2, 1, 3, 1, 1)\n",
        "\n",
        "        self.act_fnc = nn.ELU()\n",
        "        self.act_fnc2 = nn.ELU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], self.latent_dim, 1, 1)\n",
        "        x = self.act_fnc(self.conv_t_up(x))  # 4\n",
        "        x = self.res_up_block1(x)  # 8\n",
        "        x = self.res_up_block2(x)  # 16\n",
        "        x = self.res_up_block3(x)  # 32\n",
        "        x = self.res_up_block4(x)  # 32\n",
        "        x = self.res_up_block5(x)  # 32\n",
        "        x = self.res_down_block1(x)  # 32\n",
        "\n",
        "        x = self.conv_out1(x)\n",
        "        return x\n",
        "\n",
        "# Combine the encoder and decoder to form the VAE\n",
        "class ElevationVAE(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(ElevationVAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = ElevationEncoder(latent_dim)\n",
        "        self.decoder = ElevationDecoder(latent_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = mu + eps * std\n",
        "        return z\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstructed_x = self.decode(z)\n",
        "        return reconstructed_x, mu, logvar\n",
        "\n",
        "        return reconstructed_x, mu, logvar\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zWGy8kS4c4Ms"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Define the encoder network\n",
        "class LAIEncoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(LAIEncoder, self).__init__()\n",
        "        self.conv_in = nn.Conv2d(1, 16, 7, 1, 3)\n",
        "\n",
        "        self.res_down_block1 = ResDown(16,32)\n",
        "        self.res_down_block2 = ResDown(32, 64)\n",
        "        self.res_down_block3 = ResDown(64, 128)\n",
        "        self.res_down_block4 = ResDown(128, 128)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.conv_mu = nn.Linear(1152, latent_dim,)\n",
        "        self.conv_log_var = nn.Linear(1152, latent_dim)\n",
        "        self.act_fnc = nn.ELU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act_fnc(self.conv_in(x))\n",
        "\n",
        "        x = self.res_down_block1(x)  # 8\n",
        "        x = self.res_down_block2(x)  # 8\n",
        "        x = self.res_down_block3(x)  # 8\n",
        "        x = self.res_down_block4(x)  # 8\n",
        "        x = self.flatten(x)\n",
        "        mu = self.conv_mu(x)  # 1\n",
        "        logvar = self.conv_log_var(x)  # 1\n",
        "\n",
        "        return mu, logvar\n",
        "\n",
        "# Define the decoder network\n",
        "class LAIDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(LAIDecoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.act_fnc1 = nn.ELU()\n",
        "        self.conv_t_up = nn.ConvTranspose2d(latent_dim, 128, 4, 1)\n",
        "        self.res_up_block1 = ResUp(128, 64)\n",
        "        self.res_up_block2 = ResUp(64, 32)\n",
        "        self.res_up_block3 = ResUp(32, 16)\n",
        "        # self.res_up_block4 = ResUp(16,8)\n",
        "        # self.res_down_block1 = ResDown(8,4)\n",
        "        self.conv_out = nn.Conv2d(16, 1, 4, stride=1, padding=2)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], self.latent_dim, 1, 1)  # Reshape into a 5x5 tensor\n",
        "        x = self.act_fnc1(self.conv_t_up(x))  # 4\n",
        "        x = self.res_up_block1(x)  # 8\n",
        "        x = self.res_up_block2(x)  # 16\n",
        "        x = self.res_up_block3(x)  # 32\n",
        "        # x = self.res_up_block4(x)  # 32\n",
        "        # x = self.res_down_block1(x)  # 32\n",
        "        x = self.conv_out(x)\n",
        "\n",
        "        # x = torch.tanh(self.conv_out3(x))\n",
        "        return x\n",
        "\n",
        "# Combine the encoder and decoder to form the VAE\n",
        "class LAIVAE(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(LAIVAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = LAIEncoder(latent_dim)\n",
        "        self.decoder = LAIDecoder(latent_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = mu + eps * std\n",
        "        return z\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstructed_x  = self.decode(z)\n",
        "        return reconstructed_x, mu, logvar\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "axbFjlh8dGgw"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the encoder network\n",
        "class NppEncoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(NppEncoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.conv_in = nn.Conv2d(1, 4, 5, 1, 3)\n",
        "        self.res_down_block1 = ResDown(4, 8)\n",
        "        self.res_down_block2 = ResDown(8, 16)\n",
        "        self.res_down_block3 = ResDown(16,32)\n",
        "        self.res_down_block4 = ResDown(32, 64)\n",
        "        self.conv_mu = nn.Conv2d(64, latent_dim, 3, 1)\n",
        "        self.conv_log_var = nn.Conv2d(64, latent_dim, 3, 1)\n",
        "        self.act_fnc = nn.ELU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act_fnc(self.conv_in(x))\n",
        "        x = self.res_down_block1(x)  # 32\n",
        "        x = self.res_down_block2(x)  # 16\n",
        "        x = self.res_down_block3(x)  # 8\n",
        "        x = self.res_down_block4(x)  # 8\n",
        "        mu = self.conv_mu(x)  # 1\n",
        "        logvar = self.conv_log_var(x)  # 1\n",
        "\n",
        "        return mu, logvar\n",
        "\n",
        "# Define the decoder network\n",
        "class NppDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(NppDecoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.conv_t_up = nn.ConvTranspose2d(latent_dim, 256, 4, 2)\n",
        "        self.res_up_block1 = ResUp(256, 64)\n",
        "        self.res_up_block2 = ResUp(64, 32)\n",
        "        self.res_up_block3 = ResUp(32,16)\n",
        "        self.res_up_block4 = ResUp(16,8)\n",
        "        self.res_down_block1 = ResDown(8,16)\n",
        "\n",
        "\n",
        "        self.conv_out1 = nn.Conv2d(16, 1, 4, stride=1, padding=2)\n",
        "\n",
        "\n",
        "        self.act_fnc = nn.ELU()\n",
        "        self.act_fnc2 = nn.ELU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], self.latent_dim, 1, 1)\n",
        "        x = self.act_fnc(self.conv_t_up(x))  # 4\n",
        "        x = self.res_up_block1(x)  # 8\n",
        "        x = self.res_up_block2(x)  # 16\n",
        "        x = self.res_up_block3(x)  # 32\n",
        "        x = self.res_up_block4(x)  # 32\n",
        "        x = self.res_down_block1(x)\n",
        "\n",
        "\n",
        "        x = self.conv_out1(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Combine the encoder and decoder to form the VAE\n",
        "class NppVAE(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(NppVAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = NppEncoder(latent_dim)\n",
        "        self.decoder = NppDecoder(latent_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = mu + eps * std\n",
        "        return z\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstructed_x = self.decode(z)\n",
        "        return reconstructed_x, mu, logvar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MjYW0dmPdXHx"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the encoder network\n",
        "class LSTEncoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(LSTEncoder, self).__init__()\n",
        "        self.conv_in = nn.Conv2d(1, 16, 7, 1, 3)\n",
        "\n",
        "        self.res_down_block1 = ResDown(16,32)\n",
        "        self.res_down_block2 = ResDown(32, 64)\n",
        "        self.res_down_block3 = ResDown(64, 128)\n",
        "\n",
        "        self.conv_mu = nn.Conv2d(128, latent_dim, 3, 1)\n",
        "        self.conv_log_var = nn.Conv2d(128, latent_dim, 3, 1)\n",
        "        self.act_fnc = nn.ELU()\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act_fnc(self.conv_in(x))\n",
        "        x = self.res_down_block1(x)  # 32\n",
        "        x = self.res_down_block2(x)  # 16\n",
        "        x = self.res_down_block3(x)  # 8\n",
        "        mu = self.conv_mu(x)  # 1\n",
        "        logvar = self.conv_log_var(x)  # 1\n",
        "\n",
        "        return mu, logvar\n",
        "\n",
        "# Define the decoder network\n",
        "class LSTDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(LSTDecoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.conv_t_up = nn.ConvTranspose2d(latent_dim, 256, 3, 1)\n",
        "        self.res_up_block1 = ResUp(256, 128)\n",
        "        self.res_up_block2 = ResUp(128, 64)\n",
        "        self.res_up_block3 = ResUp(64,32)\n",
        "        self.conv_out1 = nn.Conv2d(32, 1, 4, stride=1, padding=1)\n",
        "\n",
        "\n",
        "\n",
        "        self.conv_out2 = nn.Conv2d(1, 16, 3, stride=1, padding=1)\n",
        "\n",
        "        self.res_up_block4 = ResUp(16,32)\n",
        "        self.res_up_block5 = ResUp(32,64)\n",
        "        self.res_down_block1 = ResDown(64, 32)\n",
        "\n",
        "        self.conv_out3 = nn.Conv2d(32, 1, 3, stride=2, padding=1)\n",
        "        # self.conv_out3 = nn.Conv2d(2, 1, 3, 1, 1)\n",
        "\n",
        "        self.act_fnc1 = nn.ELU()\n",
        "        self.act_fnc2 = nn.ELU()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], self.latent_dim, 1, 1)\n",
        "        x = self.act_fnc1(self.conv_t_up(x))  # 4\n",
        "        x = self.res_up_block1(x)  # 8\n",
        "        x = self.res_up_block2(x)  # 16\n",
        "        x = self.res_up_block3(x)\n",
        "        x = self.conv_out1(x)\n",
        "        x_final = self.conv_out2(x)\n",
        "        x_final = self.res_up_block4(x_final)  # 32\n",
        "        x_final = self.res_up_block5(x_final)  # 32\n",
        "        x_final = self.res_down_block1(x_final)\n",
        "        # x = self.act_fnc2(self.conv_out1(x))\n",
        "        x_final = self.conv_out3(x_final)\n",
        "        # x = torch.tanh(self.conv_out3(x))\n",
        "        return x_final, x\n",
        "\n",
        "# Combine the encoder and decoder to form the VAE\n",
        "class LSTVAE(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(LSTVAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = LSTEncoder(latent_dim)\n",
        "        self.decoder = LSTDecoder(latent_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        z = mu + eps * std\n",
        "        return z\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        reconstructed_x,  x_pre = self.decode(z)\n",
        "        return reconstructed_x, x_pre, mu, logvar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cmh3M7rTdeQ4"
      },
      "outputs": [],
      "source": [
        "# VaeElevation = ElevationVAE(latent_dimElevation)\n",
        "# VaeLST = LSTVAE(latent_dimLST)\n",
        "# VaeLAI = LAIVAE(latent_dimLAI)\n",
        "# VaeEvapo = EvapoVAE(latent_dimEvapo)\n",
        "# VaeNPP = NppVAE(latent_dimNPP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dVH0aX9sYwM7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ddd4f8-4a13-42ea-ee0c-17b374dad1cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-4c20310776ba>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  VaeElevation = torch.load('/content/drive/MyDrive/Colab Notebooks/vaeElevation5Epoch.pt',map_location=torch.device('cpu'))\n",
            "<ipython-input-14-4c20310776ba>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  VaeLAI = torch.load('/content/drive/MyDrive/Colab Notebooks/vaeLAI3_ME_Epoch.pt',map_location=torch.device('cpu'))\n",
            "<ipython-input-14-4c20310776ba>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  VaeNPP = torch.load('/content/drive/MyDrive/Colab Notebooks/vaeNPP5Epoch.pt',map_location=torch.device('cpu'))\n",
            "<ipython-input-14-4c20310776ba>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  VaeEvapo = torch.load('/content/drive/MyDrive/Colab Notebooks/vaeEvapo5Epoch.pt',map_location=torch.device('cpu'))\n",
            "<ipython-input-14-4c20310776ba>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  VaeLST = torch.load('/content/drive/MyDrive/Colab Notebooks/vaeLST3Epoch.pt',map_location=torch.device('cpu'))\n"
          ]
        }
      ],
      "source": [
        "VaeElevation = torch.load('/content/drive/MyDrive/Colab Notebooks/vaeElevation5Epoch.pt',map_location=torch.device('cpu'))\n",
        "VaeLAI = torch.load('/content/drive/MyDrive/Colab Notebooks/vaeLAI3_ME_Epoch.pt',map_location=torch.device('cpu'))\n",
        "VaeNPP = torch.load('/content/drive/MyDrive/Colab Notebooks/vaeNPP5Epoch.pt',map_location=torch.device('cpu'))\n",
        "VaeEvapo = torch.load('/content/drive/MyDrive/Colab Notebooks/vaeEvapo5Epoch.pt',map_location=torch.device('cpu'))\n",
        "VaeLST = torch.load('/content/drive/MyDrive/Colab Notebooks/vaeLST3Epoch.pt',map_location=torch.device('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PQtQrRpJgwSC"
      },
      "outputs": [],
      "source": [
        "# Put the model in evaluation mode\n",
        "VaeElevation.eval()\n",
        "VaeLAI.eval()\n",
        "VaeNPP.eval()\n",
        "VaeEvapo.eval()\n",
        "VaeLST.eval()\n",
        "None  # This ensures that the output is suppressed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX3-WZs3aqsG"
      },
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rHvtUYYxaqaA"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Replace the zip_file_path with the path to the zip file in your Google Drive\n",
        "zip_file_pathEvapo = '/content/drive/MyDrive/dataEvapotranspirationTensor.zip'\n",
        "zip_file_pathElevation = '/content/drive/MyDrive/dataElevationTensor.zip'\n",
        "zip_file_pathLAI = '/content/drive/MyDrive/dataLAITensor.zip'\n",
        "zip_file_pathLST = '/content/drive/MyDrive/dataLSTTensor.zip'\n",
        "zip_file_pathMODIS2015 = '/content/drive/MyDrive/dataNPPTensor.zip'\n",
        "zip_file_paths = [zip_file_pathEvapo,zip_file_pathElevation,zip_file_pathLAI,zip_file_pathLST,zip_file_pathMODIS2015]\n",
        "\n",
        "# Replace the destination_folder with the path of the folder where you want to extract the contents\n",
        "destination_folderEvapo = '/content/dataEvapotranspiration'\n",
        "destination_folderElevation = '/content/dataElevation'\n",
        "destination_folderLAI = '/content/dataLAI/'\n",
        "destination_folderLST = '/content/dataLST'\n",
        "destination_folderMODIS = '/content/dataNPP'\n",
        "destination_folders = [destination_folderEvapo,destination_folderElevation,destination_folderLAI,destination_folderLST,destination_folderMODIS]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gRalspMfgaIT"
      },
      "outputs": [],
      "source": [
        "# Unzip the file\n",
        "\n",
        "for i in range(len(destination_folders)):\n",
        "  with zipfile.ZipFile(zip_file_paths[i], 'r') as zip_ref:\n",
        "      zip_ref.extractall(destination_folders[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_f3LQMCvk8M8"
      },
      "outputs": [],
      "source": [
        "def re_scale(data, new_min, new_max):\n",
        "    # Calculate mean and center the data around zero\n",
        "    mean = data.mean()\n",
        "    min_value = data.min()\n",
        "    max_value = data.max()\n",
        "    centered_data = data - mean\n",
        "\n",
        "    scaled_data = (centered_data - min_value) / (max_value - min_value)  # Scale between 0 and 1\n",
        "    scaled_data = scaled_data * (new_max - new_min) + new_min  # Scale to new range\n",
        "\n",
        "\n",
        "    return scaled_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-Et0xPlp-6W"
      },
      "source": [
        "# Making of the Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IAkair0Jgtgd"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CustomRasterDataset(torch.utils.data.Dataset):\n",
        "    'Characterizes a dataset for PyTorch'\n",
        "    def __init__(self, dataFrame, file_path, file_extension,windowSize,re_scale = False,new_min = -1,new_max = 1):\n",
        "        'Initialization'\n",
        "        self.re_scale = re_scale\n",
        "        self.new_min  = new_min\n",
        "        self.new_max = new_max\n",
        "        self.dataFrame = dataFrame\n",
        "        self.file_path = file_path\n",
        "        self.file_extension = file_extension\n",
        "        self.windowSize = windowSize\n",
        "        self.offset = self.windowSize // 2\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.dataFrame)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        ID =  str(self.dataFrame.iloc[index]['id']) # str(ID).rstrip('.0')\n",
        "\n",
        "        x = self.dataFrame.iloc[index]['x']\n",
        "        y = self.dataFrame.iloc[index]['y']\n",
        "        OC = self.dataFrame.iloc[index]['OC']\n",
        "        point_ids = self.dataFrame.iloc[index]['point_ids']\n",
        "        # Load data and get label\n",
        "        fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
        "        # Determine the window for the square\n",
        "        left = x - self.offset\n",
        "        right = x + (self.offset + 1)\n",
        "        top = y - self.offset\n",
        "        bottom = y + (self.offset + 1)\n",
        "        X = fullArray[left:right,top:bottom].clone().detach()  # Access value in gpu_dictElevation\n",
        "        # if self.re_scale:\n",
        "          # X =  re_scale(X,self.new_min,self.new_max)\n",
        "        return X.unsqueeze(0), point_ids, OC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "MNxfIeeelKJ5"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CustomRasterDatasetSmall(torch.utils.data.Dataset):\n",
        "    'Characterizes a dataset for PyTorch'\n",
        "    def __init__(self, dataFrame, file_path, file_extension,windowSize,re_scale = False,new_min = -1,new_max = 1):\n",
        "        'Initialization'\n",
        "        self.re_scale = re_scale\n",
        "        self.new_min  = new_min\n",
        "        self.new_max = new_max\n",
        "        self.dataFrame = dataFrame\n",
        "        self.file_path = file_path\n",
        "        self.file_extension = file_extension\n",
        "        self.windowSize = windowSize\n",
        "        self.offset = self.windowSize // 2\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.dataFrame)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        ID =  str(self.dataFrame.iloc[index]['id']) # str(ID).rstrip('.0')\n",
        "\n",
        "        x = self.dataFrame.iloc[index]['x']\n",
        "        y = self.dataFrame.iloc[index]['y']\n",
        "        OC = self.dataFrame.iloc[index]['OC']\n",
        "        point_ids = self.dataFrame.iloc[index]['point_ids']\n",
        "        # Load data and get label\n",
        "        fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
        "        # Determine the window for the square\n",
        "        left = x - self.offset\n",
        "        right = x + (self.offset + 1)\n",
        "        top = y - self.offset\n",
        "        bottom = y + (self.offset + 1)\n",
        "        X = fullArray[left:right,top:bottom].clone().detach()  # Access value in gpu_dictElevation\n",
        "        # if self.re_scale:\n",
        "          # X =  re_scale(X,self.new_min,self.new_max)\n",
        "        return X.unsqueeze(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sHXbdLPxov-h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Q7_2mxEgpMfp"
      },
      "outputs": [],
      "source": [
        "batch_sizeEvapo = 1\n",
        "batch_sizeNPP = 1\n",
        "batch_sizeElevation = 1\n",
        "batch_sizeLAI = 1\n",
        "batch_sizeLST = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "w1SSYm3BpeGi"
      },
      "outputs": [],
      "source": [
        "windowSizeEvapo= 33\n",
        "windowSizeElevation = 65\n",
        "windowSizeLAI = 33\n",
        "windowSizeNPP = 33\n",
        "windowSizeLST = 23"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PKhJEEVVqS6o"
      },
      "outputs": [],
      "source": [
        "file_pathElevation = '/content/dataElevation/'\n",
        "file_pathEvapo = '/content/dataEvapotranspiration/'\n",
        "file_pathLAI = '/content/dataLAI/'\n",
        "file_pathLST = '/content/dataLST/'\n",
        "file_pathNPP = '/content/dataNPP/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jbdvVjdQq97o"
      },
      "outputs": [],
      "source": [
        "file_extension = '.pt'\n",
        "num_workers = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "R442pO4fxmay"
      },
      "outputs": [],
      "source": [
        "NppDfComp = NppDf.compute()\n",
        "LstDfComp =  LstDf.compute()\n",
        "LAIDfComp =  LAIDf.compute()\n",
        "EvapoDfComp =  EvapoDf.compute()\n",
        "ElevationDfComp =  ElevationDf.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lGIzMNjQn2iH"
      },
      "outputs": [],
      "source": [
        "# Create the dataset instance\n",
        "datasetNPP = CustomRasterDataset(NppDfComp, file_pathNPP, file_extension,windowSizeNPP)\n",
        "datasetLST = CustomRasterDataset(LstDfComp, file_pathLST, file_extension,windowSizeLST)\n",
        "datasetElevation = CustomRasterDataset(ElevationDfComp, file_pathElevation, file_extension,windowSizeElevation)\n",
        "datasetLAI = CustomRasterDataset(LAIDfComp, file_pathLAI, file_extension,windowSizeLAI)\n",
        "datasetEvapo = CustomRasterDataset(EvapoDfComp, file_pathEvapo, file_extension,windowSizeEvapo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ZR_GdNxFlO1q"
      },
      "outputs": [],
      "source": [
        "# Create the dataset instance\n",
        "dimension = 1\n",
        "datasetNPPSmall = CustomRasterDatasetSmall(NppDfComp, file_pathNPP, file_extension, dimension)\n",
        "datasetLSTSmall = CustomRasterDatasetSmall(LstDfComp, file_pathLST, file_extension,dimension)\n",
        "datasetElevationSmall = CustomRasterDatasetSmall(ElevationDfComp, file_pathElevation, file_extension, dimension)\n",
        "datasetLAISmall = CustomRasterDatasetSmall(LAIDfComp, file_pathLAI, file_extension,dimension)\n",
        "datasetEvapoSmall = CustomRasterDatasetSmall(EvapoDfComp, file_pathEvapo, file_extension,dimension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "x-Jvo5aW04bI"
      },
      "outputs": [],
      "source": [
        "dataLoaderEvapo = DataLoader(datasetEvapo, batch_size=batch_sizeEvapo, num_workers=num_workers, shuffle=False)\n",
        "dataLoaderNPP = DataLoader(datasetNPP, batch_size=batch_sizeNPP, num_workers=num_workers, shuffle=False)\n",
        "dataLoaderLST = DataLoader(datasetLST, batch_size=batch_sizeLST, num_workers=num_workers, shuffle=False)\n",
        "dataLoaderLAI = DataLoader(datasetLAI, batch_size=batch_sizeLAI, num_workers=num_workers, shuffle=False)\n",
        "dataLoaderElevation = DataLoader(datasetElevation, batch_size=batch_sizeElevation, num_workers=num_workers, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "PfCt7H46lZV8"
      },
      "outputs": [],
      "source": [
        "dataLoaderEvapoSmall = DataLoader(datasetEvapoSmall, batch_size=batch_sizeEvapo, num_workers=num_workers, shuffle=False)\n",
        "dataLoaderNPPSmall = DataLoader(datasetNPPSmall, batch_size=batch_sizeNPP, num_workers=num_workers, shuffle=False)\n",
        "dataLoaderLSTSmall = DataLoader(datasetLSTSmall, batch_size=batch_sizeLST, num_workers=num_workers, shuffle=False)\n",
        "dataLoaderLAISmall = DataLoader(datasetLAISmall, batch_size=batch_sizeLAI, num_workers=num_workers, shuffle=False)\n",
        "dataLoaderElevationSmall = DataLoader(datasetElevationSmall, batch_size=batch_sizeElevation, num_workers=num_workers, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1bz-MRmK1dSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d89412cc-9ce7-47a6-8245-fdfd4bf19b17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n"
          ]
        }
      ],
      "source": [
        "lg = next(iter(dataLoaderNPP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Sfaht5In7a1d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F51zcUj7Yh-",
        "outputId": "c9f0662a-8e2e-42bf-8439-29909017d36e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([28382290])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "lg[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODVYj5g2qEUf"
      },
      "source": [
        "# getting the Latent Space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "X1Qyt2XUNy-x"
      },
      "outputs": [],
      "source": [
        "# Check if a GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daUdII5wN2lp",
        "outputId": "d17ad1d9-94c7-45d2-991e-39f58bfea2ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTVAE(\n",
              "  (encoder): LSTEncoder(\n",
              "    (conv_in): Conv2d(1, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "    (res_down_block1): ResDown(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act_fnc): ELU(alpha=1.0)\n",
              "    )\n",
              "    (res_down_block2): ResDown(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act_fnc): ELU(alpha=1.0)\n",
              "    )\n",
              "    (res_down_block3): ResDown(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(128, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act_fnc): ELU(alpha=1.0)\n",
              "    )\n",
              "    (conv_mu): Conv2d(128, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (conv_log_var): Conv2d(128, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (act_fnc): ELU(alpha=1.0)\n",
              "  )\n",
              "  (decoder): LSTDecoder(\n",
              "    (conv_t_up): ConvTranspose2d(10, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (res_up_block1): ResUp(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(128, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(128, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (up_nn): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (act_fnc): ELU(alpha=1.0)\n",
              "    )\n",
              "    (res_up_block2): ResUp(\n",
              "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (up_nn): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (act_fnc): ELU(alpha=1.0)\n",
              "    )\n",
              "    (res_up_block3): ResUp(\n",
              "      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (up_nn): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (act_fnc): ELU(alpha=1.0)\n",
              "    )\n",
              "    (conv_out1): Conv2d(32, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
              "    (conv_out2): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (res_up_block4): ResUp(\n",
              "      (conv1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(8, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (up_nn): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (act_fnc): ELU(alpha=1.0)\n",
              "    )\n",
              "    (res_up_block5): ResUp(\n",
              "      (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (up_nn): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (act_fnc): ELU(alpha=1.0)\n",
              "    )\n",
              "    (res_down_block1): ResDown(\n",
              "      (conv1): Conv2d(64, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "      (act_fnc): ELU(alpha=1.0)\n",
              "    )\n",
              "    (conv_out3): Conv2d(32, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (act_fnc1): ELU(alpha=1.0)\n",
              "    (act_fnc2): ELU(alpha=1.0)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Move and set models to evaluation mode\n",
        "VaeElevation.to(device)\n",
        "VaeLAI.to(device)\n",
        "VaeNPP.to(device)\n",
        "VaeEvapo.to(device)\n",
        "VaeLST.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "s-7-P-rfdf_r"
      },
      "outputs": [],
      "source": [
        "latent_dimLST = 40\n",
        "latent_dimNPP = 40\n",
        "latent_dimLAI = 20\n",
        "latent_dimElevation = 10\n",
        "latent_dimEvapo = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "hYpcyTg6qGRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c95e8132-bd4b-4765-8fc6-ff142ebc357a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n"
          ]
        }
      ],
      "source": [
        "# Define your VAE classes and their associated DataLoaders\n",
        "# Assuming VaeElevation, VaeLAI, VaeNPP, VaeEvapo, and VaeLST are your VAE models\n",
        "# and dataLoaderElevation, dataLoaderLAI, dataLoaderNPP, dataLoaderEvapo, and dataLoaderLST are your DataLoaders\n",
        "\n",
        "# Define a function to save the results\n",
        "def save_results(results, file_path):\n",
        "    torch.save(results, file_path)\n",
        "\n",
        "# Initialize an optimizer if needed\n",
        "# optimizer = optim.Adam(your_model.parameters())\n",
        "\n",
        "# Define the number of epochs\n",
        "num_epochs = 1  # Adjust as needed\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    all_results = []\n",
        "\n",
        "    for  batch_npp in dataLoaderNPP:       # Move tensors or batches to the GPU\n",
        "\n",
        "        batch_nppTensor = batch_npp[0]\n",
        "\n",
        "        npp_encoded_mu, npp_encoded_logvar  = VaeNPP.encode(batch_nppTensor.to(device))\n",
        "        npp_encoded = VaeNPP.reparameterize(npp_encoded_mu, npp_encoded_logvar)\n",
        "\n",
        "\n",
        "        # Store the results along with the second and third tensors\n",
        "        result = {\n",
        "            \"npp_encoded\": npp_encoded,\n",
        "            \"point_ids\": batch_npp[1],  # Adjust for your specific use case\n",
        "            \"OC\": batch_npp[2],   # Adjust for your specific use case\n",
        "        }\n",
        "        all_results.append(result)\n",
        "\n",
        "    # Save the results for this epoch to a .pt file\n",
        "    save_results(all_results, f'epoch_vae_npp_results.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "4nVVLQClW_am",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95587c4f-02f7-48dd-846c-edd51e94da67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n"
          ]
        }
      ],
      "source": [
        "# Assuming VaeElevation, VaeLAI, VaeNPP, VaeEvapo, and VaeLST are your VAE models\n",
        "# and dataLoaderElevation, dataLoaderLAI, dataLoaderNPP, dataLoaderEvapo, and dataLoaderLST are your DataLoaders\n",
        "\n",
        "# We then define a function to save the results\n",
        "\n",
        "# Initialize an optimizer if needed\n",
        "# optimizer = optim.Adam(your_model.parameters())\n",
        "\n",
        "# Define the number of epochs\n",
        "num_epochs = 1  # Adjust as needed\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    all_results = []\n",
        "\n",
        "    for  batch_elevation in dataLoaderElevation:       # Move tensors or batches to the GPU\n",
        "        batch_elevationTensor = batch_elevation[0]\n",
        "\n",
        "        # Assuming VAE models have .encode() and .reparametrize() methods\n",
        "        elevation_encoded_mu, elevation_encoded_logvar = VaeElevation.encode(batch_elevationTensor.to(device))\n",
        "        elevation_encoded = VaeElevation.reparameterize(elevation_encoded_mu, elevation_encoded_logvar)\n",
        "\n",
        "        # Store the results along with the second and third tensors\n",
        "        result = {\n",
        "            \"elevation_encoded\": elevation_encoded,\n",
        "            \"point_ids\": batch_elevation[1],  # Adjust for your specific use case\n",
        "            \"OC\": batch_elevation[2],   # Adjust for your specific use case\n",
        "        }\n",
        "        all_results.append(result)\n",
        "\n",
        "    # Save the results for this epoch to a .pt file\n",
        "    save_results(all_results, f'epoch_vae_elevation_results.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "7czT8CFEnKxx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "qRodyum4sGnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ebacf1-e55f-443b-ff1d-e0590d680a1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n"
          ]
        }
      ],
      "source": [
        "# Define your VAE classes and their associated DataLoaders\n",
        "# Assuming VaeElevation, VaeLAI, VaeNPP, VaeEvapo, and VaeLST are your VAE models\n",
        "# and dataLoaderElevation, dataLoaderLAI, dataLoaderNPP, dataLoaderEvapo, and dataLoaderLST are your DataLoaders\n",
        "\n",
        "# Define the number of epochs\n",
        "num_epochs = 1  # Adjust as needed\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    all_results = []\n",
        "\n",
        "    for  batch_lai in dataLoaderLAI:       # Move tensors or batches to the GPU\n",
        "        # batch_elevationTensor = batch_elevation[0]\n",
        "        batch_laiTensor = batch_lai[0]\n",
        "\n",
        "        # Assuming VAE models have .encode() and .reparametrize() methods\n",
        "        lai_encoded_mu, lai_encoded_logvar  = VaeLAI.encode(batch_laiTensor.to(device))\n",
        "        lai_encoded = VaeLAI.reparameterize(lai_encoded_mu, lai_encoded_logvar)\n",
        "\n",
        "        # Store the results along with the second and third tensors\n",
        "        result = {\n",
        "            # \"elevation_encoded\": elevation_encoded,\n",
        "            \"lai_encoded\": lai_encoded.reshape(latent_dimLAI),\n",
        "            \"point_ids\": batch_lai[1],  # Adjust for your specific use case\n",
        "            \"OC\": batch_lai[2],   # Adjust for your specific use case\n",
        "        }\n",
        "        all_results.append(result)\n",
        "\n",
        "    # Save the results for this epoch to a .pt file\n",
        "    save_results(all_results, f'epoch_vae_lai_results.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdqjvLaGrd00",
        "outputId": "248e4e28-2b5b-44f7-8b0e-c2ac607f089e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n"
          ]
        }
      ],
      "source": [
        "# Define your VAE classes and their associated DataLoaders\n",
        "# Assuming VaeElevation, VaeLAI, VaeNPP, VaeEvapo, and VaeLST are your VAE models\n",
        "# and dataLoaderElevation, dataLoaderLAI, dataLoaderNPP, dataLoaderEvapo, and dataLoaderLST are your DataLoaders\n",
        "\n",
        "# Define a function to save the results\n",
        "\n",
        "# Initialize an optimizer if needed\n",
        "\n",
        "# Define the number of epochs\n",
        "num_epochs = 1  # Adjust as needed\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    all_results = []\n",
        "\n",
        "    for  batch_evapo in dataLoaderEvapo:       # Move tensors or batches to the GPU\n",
        "        batch_evapoTensor = batch_evapo[0]\n",
        "\n",
        "        # Assuming VAE models have .encode() and .reparametrize() methods\n",
        "\n",
        "        evapo_encoded_mu, evapo_encoded_logvar = VaeEvapo.encode(batch_evapoTensor.to(device))\n",
        "        evapo_encoded = VaeEvapo.reparameterize(evapo_encoded_mu, evapo_encoded_logvar)\n",
        "\n",
        "        # Store the results along with the second and third tensors\n",
        "        result = {\n",
        "\n",
        "            \"evapo_encoded\": evapo_encoded.reshape(latent_dimEvapo),\n",
        "            \"point_ids\": batch_evapo[1],  # Adjust for your specific use case\n",
        "            \"OC\": batch_evapo[2],   # Adjust for your specific use case\n",
        "        }\n",
        "        all_results.append(result)\n",
        "\n",
        "    # Save the results for this epoch to a .pt file\n",
        "    save_results(all_results, f'epoch_vae_evapo_results.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOmKtUb6XBI3",
        "outputId": "f1305e28-1622-4669-e30f-e5bdafee004d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-19-34967e8d43f8>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n"
          ]
        }
      ],
      "source": [
        "# Define your VAE classes and their associated DataLoaders\n",
        "# Assuming VaeElevation, VaeLAI, VaeNPP, VaeEvapo, and VaeLST are your VAE models\n",
        "# and dataLoaderElevation, dataLoaderLAI, dataLoaderNPP, dataLoaderEvapo, and dataLoaderLST are your DataLoaders\n",
        "\n",
        "# Define a function to save the results\n",
        "def save_results(results, file_path):\n",
        "    torch.save(results, file_path)\n",
        "\n",
        "# Define the number of epochs\n",
        "num_epochs = 1  # Adjust as needed\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    all_results = []\n",
        "\n",
        "    for  batch_lst in dataLoaderLST:       # Move tensors or batches to the GPU\n",
        "\n",
        "        batch_lstTensor = batch_lst[0]\n",
        "\n",
        "        # Assuming VAE models have .encode() and .reparametrize() methods\n",
        "\n",
        "        lst_encoded_mu, lst_encoded_logvar  = VaeLST.encode(batch_lstTensor.to(device))\n",
        "        lst_encoded = VaeLST.reparameterize(lst_encoded_mu, lst_encoded_logvar)\n",
        "\n",
        "        # Store the results along with the second and third tensors\n",
        "        result = {\n",
        "            \"lst_encoded\": lst_encoded.reshape(10),\n",
        "            \"point_ids\": batch_lst[1],  # Adjust for your specific use case\n",
        "            \"OC\": batch_lst[2],   # Adjust for your specific use case\n",
        "        }\n",
        "        all_results.append(result)\n",
        "\n",
        "    # Save the results for this epoch to a .pt file\n",
        "    save_results(all_results, f'epoch_vae_lst_results.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1ijr64CqITk"
      },
      "source": [
        "# Getting the 5 bands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "waVM18Hfn2y-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def concatenate_tensors_from_dataloader(dataloader):\n",
        "    concatenated_tensor = None\n",
        "\n",
        "    for batch in dataloader:\n",
        "        if concatenated_tensor is None:\n",
        "            concatenated_tensor = batch\n",
        "        else:\n",
        "            concatenated_tensor = torch.cat((concatenated_tensor, batch), dim=0)\n",
        "\n",
        "    return concatenated_tensor\n",
        "\n",
        "# Example usage:\n",
        "# Assuming you have a DataLoader called 'dataloader'\n",
        "# concatenated_data = concatenate_tensors_from_dataloader(dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_5nIj5vn4en",
        "outputId": "8baa584f-6acc-460b-f667-423f3cc00b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n",
            "<ipython-input-20-ac3737cc213e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  fullArray = torch.load(self.file_path+ID+self.file_extension)\n"
          ]
        }
      ],
      "source": [
        "length = 16729\n",
        "lst = concatenate_tensors_from_dataloader(dataLoaderLSTSmall).reshape((dimension,length))\n",
        "elevation = concatenate_tensors_from_dataloader(dataLoaderElevationSmall).reshape((dimension,length))\n",
        "npp = concatenate_tensors_from_dataloader(dataLoaderNPPSmall).reshape((dimension,length))\n",
        "evapo = concatenate_tensors_from_dataloader(dataLoaderEvapoSmall).reshape((dimension,length))\n",
        "lai = concatenate_tensors_from_dataloader(dataLoaderEvapoSmall).reshape((dimension,length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "w-kWq5qhpB3W"
      },
      "outputs": [],
      "source": [
        "# Create a tensor of ones of length 187\n",
        "ones_tensor = torch.ones(length).reshape((1,length))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "INbfFZESo3iW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNxqnACOs2VC"
      },
      "source": [
        "# Finish it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG4yuSTpqK8G"
      },
      "source": [
        "##Concatenating the 5 bands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yrVjGR5mDl8",
        "outputId": "b6a929a8-a4ee-404d-acfe-035c98f57ae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-43-1ce35cafeb0f>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  results = torch.load(file_path)\n",
            "<ipython-input-43-1ce35cafeb0f>:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  appended_tensor = torch.tensor(evapo_encoded).reshape((40,1))\n",
            "<ipython-input-43-1ce35cafeb0f>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  appended_tensor = torch.cat((appended_tensor, torch.tensor(evapo_encoded).reshape((40,1))),dim=1)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Initialize an empty tensor\n",
        "appended_tensor = None\n",
        "\n",
        "# Define the file path\n",
        "file_path = '/content/epoch_vae_npp_results.pt'\n",
        "\n",
        "# Load the file using torch.load\n",
        "results = torch.load(file_path)\n",
        "\n",
        "# Initialize a list to store evapo_encoded tensors\n",
        "evapo_tensors = torch.tensor([])\n",
        "\n",
        "\n",
        "# Iterate through the results and collect the evapo_encoded tensors\n",
        "for result in results:\n",
        "    evapo_encoded = result.get(\"npp_encoded\")\n",
        "\n",
        "    # Check if it's the first iteration\n",
        "    if appended_tensor is None:\n",
        "        appended_tensor = torch.tensor(evapo_encoded).reshape((40,1))\n",
        "    else:\n",
        "        # Append 'tensor_to_append' to 'appended_tensor' along dimension 0\n",
        "        appended_tensor = torch.cat((appended_tensor, torch.tensor(evapo_encoded).reshape((40,1))),dim=1)\n",
        "\n",
        "appended_tensor_npp = appended_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8jtKB7SwFzu",
        "outputId": "77fb03d4-f573-4b8d-9a17-9b62aa3f3e6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-ca28aba76534>:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  results = torch.load(file_path)\n",
            "<ipython-input-44-ca28aba76534>:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  appended_tensor = torch.tensor(evapo_encoded).reshape((50,1))\n",
            "<ipython-input-44-ca28aba76534>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  appended_tensor = torch.cat((appended_tensor, torch.tensor(evapo_encoded).reshape((50,1))),dim=1)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Initialize an empty tensor\n",
        "appended_tensor = None\n",
        "\n",
        "# Define the file path\n",
        "file_path = '/content/epoch_vae_evapo_results.pt'\n",
        "\n",
        "# Load the file using torch.load\n",
        "results = torch.load(file_path)\n",
        "\n",
        "# Initialize a list to store evapo_encoded tensors\n",
        "evapo_tensors = torch.tensor([])\n",
        "\n",
        "\n",
        "# Iterate through the results and collect the evapo_encoded tensors\n",
        "for result in results:\n",
        "    evapo_encoded = result.get(\"evapo_encoded\")\n",
        "\n",
        "    # Check if it's the first iteration\n",
        "    if appended_tensor is None:\n",
        "        appended_tensor = torch.tensor(evapo_encoded).reshape((50,1))\n",
        "    else:\n",
        "        # Append 'tensor_to_append' to 'appended_tensor' along dimension 0\n",
        "        appended_tensor = torch.cat((appended_tensor, torch.tensor(evapo_encoded).reshape((50,1))),dim=1)\n",
        "\n",
        "appended_tensor_evapo = appended_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAybEl_j0S2W",
        "outputId": "951cd1d5-1522-49c4-dce4-6ae1ad26ea1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 16729])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "\n",
        "appended_tensor_evapo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "daI9XI9TdnkA"
      },
      "outputs": [],
      "source": [
        "latent_dimLST = 10\n",
        "latent_dimLAI = 20\n",
        "latent_Elevation = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJI8303qXPD0",
        "outputId": "4502a47d-e390-4930-e919-af5d43f67c7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-a80f98423c62>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  results = torch.load(file_path)\n",
            "<ipython-input-47-a80f98423c62>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  appended_tensor = torch.tensor(evapo_encoded).reshape((10,1))\n",
            "<ipython-input-47-a80f98423c62>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  appended_tensor = torch.cat((appended_tensor, torch.tensor(evapo_encoded).reshape((latent_dimLST,1))),dim=1)\n"
          ]
        }
      ],
      "source": [
        "# Initialize an empty tensor\n",
        "appended_tensor = None\n",
        "\n",
        "# Define the file path\n",
        "file_path = '/content/epoch_vae_lst_results.pt'\n",
        "\n",
        "# Load the file using torch.load\n",
        "results = torch.load(file_path)\n",
        "\n",
        "# Initialize a list to store evapo_encoded tensors\n",
        "evapo_tensors = torch.tensor([])\n",
        "\n",
        "\n",
        "# Iterate through the results and collect the evapo_encoded tensors\n",
        "for result in results:\n",
        "    evapo_encoded = result.get(\"lst_encoded\")\n",
        "\n",
        "    # Check if it's the first iteration\n",
        "    if appended_tensor is None:\n",
        "        appended_tensor = torch.tensor(evapo_encoded).reshape((10,1))\n",
        "    else:\n",
        "        # Append 'tensor_to_append' to 'appended_tensor' along dimension 0\n",
        "        appended_tensor = torch.cat((appended_tensor, torch.tensor(evapo_encoded).reshape((latent_dimLST,1))),dim=1)\n",
        "\n",
        "appended_tensor_lst = appended_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "2f-8_hOlnM07"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Cj1CRIi3DYq",
        "outputId": "1fd5e42d-96ca-43f0-faca-a0f4d15325f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-47a955b0e8eb>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  results = torch.load(file_path)\n",
            "<ipython-input-48-47a955b0e8eb>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  appended_tensor = torch.tensor(evapo_encoded).reshape((latent_Elevation,1))\n",
            "<ipython-input-48-47a955b0e8eb>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  appended_tensor = torch.cat((appended_tensor, torch.tensor(evapo_encoded).reshape((latent_Elevation,1))),dim=1)\n"
          ]
        }
      ],
      "source": [
        "# Initialize an empty tensor\n",
        "appended_tensor = None\n",
        "\n",
        "# Define the file path\n",
        "file_path = '/content/epoch_vae_elevation_results.pt'\n",
        "\n",
        "# Load the file using torch.load\n",
        "results = torch.load(file_path)\n",
        "\n",
        "# Initialize a list to store evapo_encoded tensors\n",
        "evapo_tensors = torch.tensor([])\n",
        "\n",
        "\n",
        "# Iterate through the results and collect the evapo_encoded tensors\n",
        "for result in results:\n",
        "    evapo_encoded = result.get(\"elevation_encoded\")\n",
        "\n",
        "    # Check if it's the first iteration\n",
        "    if appended_tensor is None:\n",
        "        appended_tensor = torch.tensor(evapo_encoded).reshape((latent_Elevation,1))\n",
        "    else:\n",
        "        # Append 'tensor_to_append' to 'appended_tensor' along dimension 0\n",
        "        appended_tensor = torch.cat((appended_tensor, torch.tensor(evapo_encoded).reshape((latent_Elevation,1))),dim=1)\n",
        "\n",
        "appended_tensor_elevation = appended_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le7Cg_XbwJ3q",
        "outputId": "4bbee610-bc68-4450-d102-db8027af8c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-45ebfe3faaea>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  results = torch.load(file_path)\n",
            "<ipython-input-49-45ebfe3faaea>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  appended_tensor = torch.tensor(evapo_encoded).reshape((latent_dimLAI,1))\n",
            "<ipython-input-49-45ebfe3faaea>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  appended_tensor = torch.cat((appended_tensor, torch.tensor(evapo_encoded).reshape((latent_dimLAI,1))),dim=1)\n"
          ]
        }
      ],
      "source": [
        "# Initialize an empty tensor\n",
        "appended_tensor = None\n",
        "\n",
        "# Define the file path\n",
        "file_path = '/content/epoch_vae_lai_results.pt'\n",
        "\n",
        "# Load the file using torch.load\n",
        "results = torch.load(file_path)\n",
        "\n",
        "# Initialize a list to store evapo_encoded tensors\n",
        "evapo_tensors = torch.tensor([])\n",
        "\n",
        "\n",
        "# Iterate through the results and collect the evapo_encoded tensors\n",
        "for result in results:\n",
        "    evapo_encoded = result.get(\"lai_encoded\")\n",
        "\n",
        "    # Check if it's the first iteration\n",
        "    if appended_tensor is None:\n",
        "        appended_tensor = torch.tensor(evapo_encoded).reshape((latent_dimLAI,1))\n",
        "    else:\n",
        "        # Append 'tensor_to_append' to 'appended_tensor' along dimension 0\n",
        "        appended_tensor = torch.cat((appended_tensor, torch.tensor(evapo_encoded).reshape((latent_dimLAI,1))),dim=1)\n",
        "\n",
        "appended_tensor_lai = appended_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJsg_dx64KVy",
        "outputId": "28fab3ec-9c36-454d-b526-6ddc41c696e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-59ecf27fca2a>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  results = torch.load(file_path)\n",
            "<ipython-input-50-59ecf27fca2a>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  appended_tensor = torch.tensor(evapo_encoded).reshape((dimension,1))\n",
            "<ipython-input-50-59ecf27fca2a>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  appended_tensor = torch.cat((appended_tensor, torch.tensor(evapo_encoded).reshape((dimension,1))),dim=1)\n"
          ]
        }
      ],
      "source": [
        "# Initialize an empty tensor\n",
        "appended_tensor = None\n",
        "\n",
        "# Define the file path\n",
        "file_path = '/content/epoch_vae_lai_results.pt'\n",
        "\n",
        "# Load the file using torch.load\n",
        "results = torch.load(file_path)\n",
        "\n",
        "# Initialize a list to store evapo_encoded tensors\n",
        "evapo_tensors = torch.tensor([])\n",
        "\n",
        "\n",
        "# Iterate through the results and collect the evapo_encoded tensors\n",
        "for result in results:\n",
        "    evapo_encoded = result.get(\"OC\")\n",
        "\n",
        "    # Check if it's the first iteration\n",
        "    if appended_tensor is None:\n",
        "        appended_tensor = torch.tensor(evapo_encoded).reshape((dimension,1))\n",
        "    else:\n",
        "        # Append 'tensor_to_append' to 'appended_tensor' along dimension 0\n",
        "        appended_tensor = torch.cat((appended_tensor, torch.tensor(evapo_encoded).reshape((dimension,1))),dim=1)\n",
        "\n",
        "appended_tensor_OC = appended_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rL6YLcgsw5E",
        "outputId": "5e1098a2-305b-4d0a-e174-74230033a2a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1.,  ..., 1., 1., 1.]]),\n",
              " tensor([[14826.9131, 14995.0000, 14947.6953,  ..., 14394.1816, 14328.2002,\n",
              "          14288.0000]]),\n",
              " tensor([[774., 461.,  33.,  ..., 107., 370., 449.]]),\n",
              " tensor([[243.0000, 248.9091, 185.2174,  ..., 167.6364, 132.8571, 112.3077]]),\n",
              " tensor([[243.0000, 248.9091, 185.2174,  ..., 167.6364, 132.8571, 112.3077]]),\n",
              " tensor([[ 8900.,  8703., 10287.,  ...,  5123.,  3742.,  4813.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "ones_tensor,lst,elevation,lai,evapo,npp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "dJd-iS1anPpc"
      },
      "outputs": [],
      "source": [
        "smallX = torch.cat((ones_tensor,lst,elevation,lai,evapo,npp),dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Sp1xwpcsuBk"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5yVkgu5qPj_"
      },
      "source": [
        "### We are putting it together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7Uo5nDAzsx0",
        "outputId": "430f2d97-534c-4a46-ade2-4e9f71d91107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evapo: torch.Size([50, 16729])\n",
            "LAI: torch.Size([20, 16729])\n",
            "Elevation: torch.Size([40, 16729])\n",
            "LST: torch.Size([10, 16729])\n",
            "NPP: torch.Size([40, 16729])\n"
          ]
        }
      ],
      "source": [
        "print('Evapo:',appended_tensor_evapo.shape)\n",
        "print('LAI:',appended_tensor_lai.shape)\n",
        "print('Elevation:',appended_tensor_elevation.shape)\n",
        "print('LST:',appended_tensor_lst.shape)\n",
        "print('NPP:',appended_tensor_npp.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "45gnLw3q35a_"
      },
      "outputs": [],
      "source": [
        "ones_tensor = ones_tensor.to(device)\n",
        "appended_tensor_X = torch.cat((ones_tensor.to(device),appended_tensor_evapo,appended_tensor_lai,appended_tensor_elevation,appended_tensor_lst,appended_tensor_npp),dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "GDCZybrn0CRC"
      },
      "outputs": [],
      "source": [
        "NN_X = torch.cat((appended_tensor_evapo,appended_tensor_lai,appended_tensor_elevation,appended_tensor_lst,appended_tensor_npp),dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94DQfgB07JCj"
      },
      "source": [
        "# Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmLa4m2xb7rf"
      },
      "source": [
        "## Smaller Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMnBoxIApQJU",
        "outputId": "bab658da-816d-4839-d0dc-94d0b34287a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.142\n",
            "Model:                            OLS   Adj. R-squared:                  0.142\n",
            "Method:                 Least Squares   F-statistic:                     694.1\n",
            "Date:                Sun, 13 Oct 2024   Prob (F-statistic):               0.00\n",
            "Time:                        21:14:29   Log-Likelihood:                -95032.\n",
            "No. Observations:               16729   AIC:                         1.901e+05\n",
            "Df Residuals:                   16724   BIC:                         1.901e+05\n",
            "Df Model:                           4                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const       1488.5202     29.192     50.991      0.000    1431.302    1545.739\n",
            "x1            -0.0974      0.002    -50.560      0.000      -0.101      -0.094\n",
            "x2             0.0176      0.002     11.355      0.000       0.015       0.021\n",
            "x3            -0.0805      0.006    -13.259      0.000      -0.092      -0.069\n",
            "x4            -0.0805      0.006    -13.259      0.000      -0.092      -0.069\n",
            "x5             0.0037      0.000      9.007      0.000       0.003       0.005\n",
            "==============================================================================\n",
            "Omnibus:                    13421.598   Durbin-Watson:                   1.729\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           268290.834\n",
            "Skew:                           3.875   Prob(JB):                         0.00\n",
            "Kurtosis:                      21.023   Cond. No.                     9.36e+17\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 4.93e-24. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Assuming 'X' is your input features and 'Y' is your target values as NumPy arrays\n",
        "X = np.array(smallX.T)\n",
        "Y = np.array(appended_tensor_OC.T)\n",
        "\n",
        "# Define the Tobit model with left-censoring (use 'r' for right-censoring)\n",
        "tobit_model = sm.OLS(Y, X,'l')  # Ordinary Least Squares (OLS) with censored data\n",
        "\n",
        "# Fit the Tobit model\n",
        "results = tobit_model.fit()\n",
        "\n",
        "# Print the summary of the Tobit regression results\n",
        "print(results.summary())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91-joUj7b-vs"
      },
      "source": [
        "## Larger Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKfuo2wrFrl0",
        "outputId": "38a018f5-699a-4570-a96d-f938cea949dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.186\n",
            "Model:                            OLS   Adj. R-squared:                  0.178\n",
            "Method:                 Least Squares   F-statistic:                     23.61\n",
            "Date:                Sun, 13 Oct 2024   Prob (F-statistic):               0.00\n",
            "Time:                        21:14:30   Log-Likelihood:                -94599.\n",
            "No. Observations:               16729   AIC:                         1.895e+05\n",
            "Df Residuals:                   16568   BIC:                         1.908e+05\n",
            "Df Model:                         160                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         94.0931      8.289     11.351      0.000      77.845     110.341\n",
            "x1            -0.0334      0.147     -0.226      0.821      -0.322       0.256\n",
            "x2            -0.1910      0.138     -1.385      0.166      -0.461       0.079\n",
            "x3             0.0045      0.141      0.032      0.975      -0.271       0.280\n",
            "x4             0.7731      0.148      5.210      0.000       0.482       1.064\n",
            "x5            -0.1573      0.127     -1.239      0.215      -0.406       0.092\n",
            "x6             0.2593      0.142      1.823      0.068      -0.019       0.538\n",
            "x7            -0.1170      0.149     -0.785      0.433      -0.409       0.175\n",
            "x8            -0.1758      0.138     -1.272      0.203      -0.447       0.095\n",
            "x9            -0.0782      0.142     -0.551      0.582      -0.356       0.200\n",
            "x10           -0.9452      0.136     -6.963      0.000      -1.211      -0.679\n",
            "x11           -0.1757      0.142     -1.236      0.217      -0.454       0.103\n",
            "x12            0.0710      0.147      0.483      0.629      -0.217       0.359\n",
            "x13           -0.8994      0.140     -6.404      0.000      -1.175      -0.624\n",
            "x14           -0.2911      0.139     -2.093      0.036      -0.564      -0.018\n",
            "x15            0.0290      0.134      0.216      0.829      -0.234       0.292\n",
            "x16           -0.3567      0.156     -2.280      0.023      -0.663      -0.050\n",
            "x17           -0.6222      0.160     -3.885      0.000      -0.936      -0.308\n",
            "x18           -0.2235      0.146     -1.535      0.125      -0.509       0.062\n",
            "x19            0.7365      0.146      5.035      0.000       0.450       1.023\n",
            "x20            0.2648      0.133      1.990      0.047       0.004       0.526\n",
            "x21            0.3256      0.145      2.251      0.024       0.042       0.609\n",
            "x22           -0.2436      0.154     -1.583      0.114      -0.545       0.058\n",
            "x23           -0.6808      0.136     -5.009      0.000      -0.947      -0.414\n",
            "x24            0.2618      0.139      1.889      0.059      -0.010       0.533\n",
            "x25            0.1294      0.166      0.778      0.437      -0.197       0.455\n",
            "x26            0.1240      0.134      0.925      0.355      -0.139       0.387\n",
            "x27            0.0143      0.152      0.094      0.925      -0.283       0.311\n",
            "x28            0.0509      0.149      0.342      0.732      -0.241       0.343\n",
            "x29            0.3012      0.146      2.068      0.039       0.016       0.587\n",
            "x30           -0.0206      0.151     -0.137      0.891      -0.316       0.275\n",
            "x31           -0.2482      0.143     -1.732      0.083      -0.529       0.033\n",
            "x32            0.0024      0.150      0.016      0.987      -0.292       0.296\n",
            "x33            0.3419      0.155      2.210      0.027       0.039       0.645\n",
            "x34           -0.1044      0.138     -0.757      0.449      -0.375       0.166\n",
            "x35            0.0230      0.138      0.167      0.868      -0.247       0.293\n",
            "x36            1.0699      0.152      7.059      0.000       0.773       1.367\n",
            "x37            0.2327      0.145      1.600      0.110      -0.052       0.518\n",
            "x38            0.1199      0.146      0.822      0.411      -0.166       0.406\n",
            "x39           -1.2416      0.128     -9.694      0.000      -1.493      -0.991\n",
            "x40            0.3344      0.147      2.279      0.023       0.047       0.622\n",
            "x41           -0.0039      0.151     -0.026      0.979      -0.300       0.292\n",
            "x42            0.0401      0.147      0.273      0.785      -0.248       0.328\n",
            "x43           -0.1460      0.143     -1.021      0.307      -0.426       0.134\n",
            "x44           -0.9084      0.160     -5.675      0.000      -1.222      -0.595\n",
            "x45           -0.0843      0.148     -0.569      0.569      -0.375       0.206\n",
            "x46           -0.5665      0.164     -3.465      0.001      -0.887      -0.246\n",
            "x47            0.4991      0.169      2.959      0.003       0.168       0.830\n",
            "x48            0.0844      0.146      0.577      0.564      -0.202       0.371\n",
            "x49            0.4507      0.153      2.954      0.003       0.152       0.750\n",
            "x50           -0.2354      0.139     -1.699      0.089      -0.507       0.036\n",
            "x51            2.4326      0.673      3.616      0.000       1.114       3.751\n",
            "x52            2.0008      0.791      2.530      0.011       0.451       3.551\n",
            "x53            1.6966      0.603      2.815      0.005       0.515       2.878\n",
            "x54           -1.0495      0.628     -1.672      0.095      -2.280       0.181\n",
            "x55            2.8735      0.686      4.191      0.000       1.530       4.217\n",
            "x56            0.0416      0.591      0.070      0.944      -1.117       1.200\n",
            "x57           -0.2232      0.589     -0.379      0.705      -1.378       0.932\n",
            "x58            0.3988      0.651      0.613      0.540      -0.877       1.675\n",
            "x59           25.3878      1.651     15.373      0.000      22.151      28.625\n",
            "x60            1.9456      0.634      3.070      0.002       0.703       3.188\n",
            "x61            1.8013      0.756      2.382      0.017       0.319       3.284\n",
            "x62            3.1772      0.722      4.399      0.000       1.761       4.593\n",
            "x63           -5.5663      0.639     -8.716      0.000      -6.818      -4.314\n",
            "x64           -1.3522      0.575     -2.352      0.019      -2.479      -0.226\n",
            "x65           -0.1312      0.622     -0.211      0.833      -1.350       1.087\n",
            "x66            0.1779      0.643      0.277      0.782      -1.082       1.437\n",
            "x67           -0.8384      0.714     -1.175      0.240      -2.237       0.561\n",
            "x68            2.6859      0.826      3.253      0.001       1.067       4.304\n",
            "x69            0.2894      0.638      0.454      0.650      -0.961       1.540\n",
            "x70           -1.1241      0.636     -1.768      0.077      -2.370       0.122\n",
            "x71            0.0895      0.155      0.578      0.563      -0.214       0.393\n",
            "x72           -0.0707      0.176     -0.401      0.688      -0.416       0.275\n",
            "x73           -0.0159      0.157     -0.101      0.920      -0.324       0.292\n",
            "x74            0.0095      0.200      0.047      0.962      -0.382       0.401\n",
            "x75           -0.0502      0.192     -0.262      0.793      -0.426       0.326\n",
            "x76           -0.0174      0.172     -0.101      0.919      -0.354       0.319\n",
            "x77           -0.3048      0.159     -1.914      0.056      -0.617       0.007\n",
            "x78           -0.0736      0.194     -0.379      0.704      -0.454       0.307\n",
            "x79           -0.2397      0.221     -1.084      0.278      -0.673       0.194\n",
            "x80            0.1788      0.195      0.918      0.359      -0.203       0.561\n",
            "x81           -0.3227      0.199     -1.625      0.104      -0.712       0.066\n",
            "x82           -0.0571      0.181     -0.315      0.753      -0.413       0.299\n",
            "x83           -0.1960      0.124     -1.576      0.115      -0.440       0.048\n",
            "x84           -0.0576      0.166     -0.348      0.728      -0.382       0.267\n",
            "x85           -0.0203      0.189     -0.108      0.914      -0.390       0.350\n",
            "x86           -0.1083      0.177     -0.612      0.541      -0.456       0.239\n",
            "x87            0.0656      0.190      0.346      0.730      -0.307       0.438\n",
            "x88            0.0627      0.148      0.422      0.673      -0.228       0.354\n",
            "x89           -0.3315      0.193     -1.718      0.086      -0.710       0.047\n",
            "x90           -0.1927      0.159     -1.212      0.225      -0.504       0.119\n",
            "x91           -0.0658      0.185     -0.356      0.722      -0.427       0.296\n",
            "x92            0.2734      0.156      1.750      0.080      -0.033       0.580\n",
            "x93            0.0581      0.167      0.347      0.728      -0.270       0.386\n",
            "x94            0.0755      0.188      0.402      0.688      -0.293       0.444\n",
            "x95           -0.2781      0.169     -1.643      0.100      -0.610       0.054\n",
            "x96           -0.1068      0.173     -0.617      0.537      -0.446       0.232\n",
            "x97            0.0979      0.168      0.583      0.560      -0.231       0.427\n",
            "x98           -0.0935      0.154     -0.607      0.544      -0.395       0.208\n",
            "x99           -0.0029      0.207     -0.014      0.989      -0.409       0.403\n",
            "x100          -0.0153      0.156     -0.098      0.922      -0.320       0.290\n",
            "x101           0.0680      0.154      0.443      0.658      -0.233       0.369\n",
            "x102           0.2462      0.142      1.729      0.084      -0.033       0.525\n",
            "x103           0.0477      0.210      0.227      0.820      -0.364       0.459\n",
            "x104           0.1481      0.188      0.787      0.431      -0.221       0.517\n",
            "x105          -0.5349      0.202     -2.647      0.008      -0.931      -0.139\n",
            "x106          -0.4589      0.190     -2.420      0.016      -0.831      -0.087\n",
            "x107          -0.1337      0.200     -0.667      0.505      -0.526       0.259\n",
            "x108          -0.0292      0.202     -0.145      0.885      -0.424       0.366\n",
            "x109          -0.3020      0.162     -1.859      0.063      -0.620       0.016\n",
            "x110          -0.2022      0.182     -1.110      0.267      -0.559       0.155\n",
            "x111          -9.3798      0.595    -15.777      0.000     -10.545      -8.215\n",
            "x112           0.3221      0.634      0.508      0.611      -0.920       1.564\n",
            "x113          -0.2198      0.662     -0.332      0.740      -1.517       1.078\n",
            "x114          -0.9071      0.822     -1.104      0.270      -2.518       0.704\n",
            "x115          -1.3673      0.880     -1.554      0.120      -3.092       0.358\n",
            "x116           0.0536      0.818      0.066      0.948      -1.550       1.657\n",
            "x117          -0.1768      0.646     -0.274      0.784      -1.443       1.090\n",
            "x118          -0.2546      0.678     -0.375      0.707      -1.584       1.075\n",
            "x119          -0.7564      0.593     -1.276      0.202      -1.918       0.405\n",
            "x120          -0.4746      0.735     -0.646      0.518      -1.915       0.966\n",
            "x121           0.2559      0.173      1.479      0.139      -0.083       0.595\n",
            "x122           0.0083      0.160      0.052      0.959      -0.305       0.322\n",
            "x123          -0.1135      0.177     -0.641      0.521      -0.460       0.233\n",
            "x124           0.2498      0.123      2.037      0.042       0.009       0.490\n",
            "x125          -0.0766      0.144     -0.533      0.594      -0.358       0.205\n",
            "x126           0.2794      0.156      1.787      0.074      -0.027       0.586\n",
            "x127           0.0062      0.157      0.039      0.969      -0.301       0.314\n",
            "x128          -0.3950      0.163     -2.417      0.016      -0.715      -0.075\n",
            "x129          -0.2591      0.164     -1.585      0.113      -0.580       0.061\n",
            "x130           0.2215      0.169      1.314      0.189      -0.109       0.552\n",
            "x131           0.2124      0.138      1.533      0.125      -0.059       0.484\n",
            "x132           0.4599      0.211      2.175      0.030       0.046       0.874\n",
            "x133           0.1110      0.166      0.669      0.503      -0.214       0.436\n",
            "x134          -0.3173      0.152     -2.081      0.037      -0.616      -0.018\n",
            "x135           0.2581      0.160      1.617      0.106      -0.055       0.571\n",
            "x136          -0.0950      0.151     -0.627      0.531      -0.392       0.202\n",
            "x137           0.0081      0.140      0.058      0.954      -0.267       0.283\n",
            "x138          -0.3557      0.145     -2.452      0.014      -0.640      -0.071\n",
            "x139          -0.0896      0.158     -0.569      0.570      -0.398       0.219\n",
            "x140          -0.1673      0.159     -1.051      0.293      -0.479       0.145\n",
            "x141          -0.0336      0.119     -0.283      0.777      -0.266       0.199\n",
            "x142          -0.0285      0.158     -0.180      0.857      -0.339       0.282\n",
            "x143           0.3188      0.172      1.855      0.064      -0.018       0.656\n",
            "x144           0.0824      0.192      0.429      0.668      -0.294       0.459\n",
            "x145           0.2581      0.154      1.681      0.093      -0.043       0.559\n",
            "x146           0.0404      0.157      0.257      0.797      -0.268       0.349\n",
            "x147           0.4829      0.154      3.132      0.002       0.181       0.785\n",
            "x148          -0.1432      0.158     -0.907      0.364      -0.453       0.166\n",
            "x149          -0.0392      0.158     -0.248      0.804      -0.350       0.271\n",
            "x150           0.1028      0.159      0.645      0.519      -0.210       0.415\n",
            "x151           0.3166      0.154      2.051      0.040       0.014       0.619\n",
            "x152           0.2263      0.190      1.191      0.234      -0.146       0.599\n",
            "x153           0.4932      0.162      3.037      0.002       0.175       0.812\n",
            "x154           0.1510      0.157      0.962      0.336      -0.157       0.458\n",
            "x155          -0.3629      0.172     -2.108      0.035      -0.700      -0.025\n",
            "x156           0.0341      0.171      0.199      0.842      -0.302       0.370\n",
            "x157          -0.0153      0.159     -0.096      0.923      -0.327       0.296\n",
            "x158          -0.0326      0.155     -0.211      0.833      -0.336       0.271\n",
            "x159          -0.0386      0.166     -0.233      0.816      -0.364       0.286\n",
            "x160          -0.7003      0.157     -4.466      0.000      -1.008      -0.393\n",
            "==============================================================================\n",
            "Omnibus:                    13033.236   Durbin-Watson:                   1.790\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           250645.305\n",
            "Skew:                           3.720   Prob(JB):                         0.00\n",
            "Kurtosis:                      20.442   Cond. No.                         888.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Assuming 'appended_tensor_X' and 'appended_tensor_OC' are your input features and target values as PyTorch tensors\n",
        "X = np.array(appended_tensor_X.T.cpu())  # Move tensor to CPU before converting\n",
        "Y = np.array(appended_tensor_OC.T.cpu())  # Move tensor to CPU before converting\n",
        "\n",
        "# Define the Tobit model with left-censoring (use 'r' for right-censoring)\n",
        "# Note: There seems to be a misunderstanding in your use of 'sm.OLS'. Ordinary Least Squares (OLS) does not inherently handle censored data.\n",
        "# If you intend to use a censored regression model, consider using an appropriate method or package that supports censored data.\n",
        "tobit_model = sm.OLS(Y, X)  # OLS regression model (for demonstration)\n",
        "\n",
        "# Fit the Tobit model\n",
        "results = tobit_model.fit()\n",
        "\n",
        "# Print the summary of the regression results\n",
        "print(results.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gea0dow2cBbj"
      },
      "source": [
        "## Regression on the Best Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRgcpG8ZSqCe",
        "outputId": "0ac70ef2-6dcc-48f3-e416-33b24bc75739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPhkjIwEzg1j",
        "outputId": "4f767f15-a125-461c-f1f5-e2fffb6e9041"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   4,  10,  13,  17,  19,  23,  36,  39,  44,  46,  47,  49,\n",
              "        51,  53,  55,  59,  60,  62,  63,  68, 105, 111, 147, 153, 160])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "np.where(results.pvalues < 0.01)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGULEfZ5xQ3S",
        "outputId": "6b64f787-22d1-424c-99b0-f16eddd708e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.171\n",
            "Model:                            OLS   Adj. R-squared:                  0.169\n",
            "Method:                 Least Squares   F-statistic:                     137.6\n",
            "Date:                Sun, 13 Oct 2024   Prob (F-statistic):               0.00\n",
            "Time:                        21:14:30   Log-Likelihood:                -94751.\n",
            "No. Observations:               16729   AIC:                         1.896e+05\n",
            "Df Residuals:                   16703   BIC:                         1.898e+05\n",
            "Df Model:                          25                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         82.9579      2.568     32.308      0.000      77.925      87.991\n",
            "x1             0.6267      0.127      4.950      0.000       0.379       0.875\n",
            "x2            -0.9070      0.124     -7.290      0.000      -1.151      -0.663\n",
            "x3            -1.0528      0.119     -8.854      0.000      -1.286      -0.820\n",
            "x4            -0.5728      0.135     -4.246      0.000      -0.837      -0.308\n",
            "x5             0.5987      0.132      4.534      0.000       0.340       0.857\n",
            "x6            -0.3678      0.116     -3.172      0.002      -0.595      -0.141\n",
            "x7             1.0658      0.123      8.667      0.000       0.825       1.307\n",
            "x8            -1.2595      0.114    -11.032      0.000      -1.483      -1.036\n",
            "x9            -0.5446      0.130     -4.194      0.000      -0.799      -0.290\n",
            "x10           -0.4713      0.128     -3.684      0.000      -0.722      -0.221\n",
            "x11            0.4339      0.130      3.333      0.001       0.179       0.689\n",
            "x12            0.2988      0.134      2.230      0.026       0.036       0.561\n",
            "x13            1.9433      0.564      3.444      0.001       0.837       3.049\n",
            "x14            1.6533      0.550      3.005      0.003       0.575       2.732\n",
            "x15            2.7440      0.614      4.466      0.000       1.540       3.948\n",
            "x16           26.8644      1.358     19.781      0.000      24.202      29.526\n",
            "x17            2.1204      0.569      3.726      0.000       1.005       3.236\n",
            "x18            3.6023      0.611      5.895      0.000       2.404       4.800\n",
            "x19           -5.5297      0.520    -10.637      0.000      -6.549      -4.511\n",
            "x20            3.2508      0.615      5.289      0.000       2.046       4.456\n",
            "x21           -0.9896      0.152     -6.495      0.000      -1.288      -0.691\n",
            "x22           -8.4360      0.408    -20.658      0.000      -9.236      -7.636\n",
            "x23            0.2803      0.133      2.114      0.035       0.020       0.540\n",
            "x24            0.5112      0.146      3.501      0.000       0.225       0.797\n",
            "x25           -0.6046      0.139     -4.340      0.000      -0.878      -0.332\n",
            "==============================================================================\n",
            "Omnibus:                    13102.771   Durbin-Watson:                   1.764\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           252492.651\n",
            "Skew:                           3.750   Prob(JB):                         0.00\n",
            "Kurtosis:                      20.493   Cond. No.                         69.8\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Examine summary statistics to identify significant features\n",
        "# Look at p-values in the summary and choose a significance level (e.g., 0.05)\n",
        "significant_features = np.where(results.pvalues < 0.01)[0]\n",
        "\n",
        "\n",
        "# Step 2: Filter the significant features\n",
        "X_significant = X[:, significant_features]\n",
        "\n",
        "# Step 3: Perform regression using only the significant features\n",
        "tobit_model_significant = sm.OLS(Y, X_significant)\n",
        "results_significant = tobit_model_significant.fit()\n",
        "\n",
        "# Print the summary of the regression results with only significant features\n",
        "print(results_significant.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "AYaIw-6ybe7c"
      },
      "outputs": [],
      "source": [
        "# appended_tensor_X = appended_tensor_lst\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkOPnVRD4GPS",
        "outputId": "d70abc9a-3f29-4916-9667-8d681617fdb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([161, 16729])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "appended_tensor_X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gexwNjM4QNI",
        "outputId": "4678997b-e3be-4887-82b6-a67523c8f58d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16729])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "appended_tensor_OC.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPFNAlV20gTK"
      },
      "source": [
        "# Some Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "dfcukTji5fj8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "3JLMY6cM5G5n"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Assuming 'X' is your input features and 'Y' is your target values as NumPy arrays\n",
        "X = np.array(appended_tensor_X.T.cpu())\n",
        "Y = np.array(appended_tensor_OC.T.cpu())\n",
        "\n",
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model to the data\n",
        "model.fit(X, Y)\n",
        "\n",
        "# Get the coefficients and intercept\n",
        "coefficients = model.coef_\n",
        "intercept = model.intercept_\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYGc6T746aD7",
        "outputId": "9194dcbb-0ecf-461f-f486-5366216149af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R-squared: 0.1856889683454429\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Calculate the R-squared value\n",
        "r_squared = r2_score(Y, predictions)\n",
        "\n",
        "# Print the R-squared value\n",
        "print(\"R-squared:\", r_squared)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNht43KE6-Ty",
        "outputId": "700477b6-e598-4635-b773-3a20d45db270"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69.11972630603873"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "rmse = np.sqrt(mean_squared_error(Y, predictions))\n",
        "rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCGCjY5W8ZZx",
        "outputId": "ab860ff8-e135-417c-8186-1c2984d4379d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13666291508737616"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split your data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Calculate adjusted R-squared\n",
        "n = len(Y_test)\n",
        "p = X_test.shape[1]  # Number of predictors\n",
        "r_squared = r2_score(Y_test, predictions)\n",
        "adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
        "adjusted_r_squared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w0CrHZ8sQeX",
        "outputId": "b1728266-db3a-4f74-a58b-11ff2b4e3412"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1658792964707081"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "# Split your data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_significant, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Calculate adjusted R-squared\n",
        "n = len(Y_test)\n",
        "p = X_test.shape[1]  # Number of predictors\n",
        "r_squared = r2_score(Y_test, predictions)\n",
        "adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
        "adjusted_r_squared"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wmc32Rzs30w"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIqORlsoxCBX",
        "outputId": "aa991aa6-98b2-4654-8d9f-c1be67a62e7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-69-dfce0ebce7a5>:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  results = torch.load(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The order of point_ids is the same for all files.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Define file paths for the three files\n",
        "file_paths = [\n",
        "    '/content/epoch_vae_evapo_results.pt',\n",
        "    '/content/epoch_vae_lai_results.pt',\n",
        "    '/content/epoch_vae_lst_results.pt',\n",
        "]\n",
        "\n",
        "# Initialize lists to store point_ids from each file\n",
        "point_ids_lists = []\n",
        "\n",
        "# Load data and extract point_ids from each file\n",
        "for file_path in file_paths:\n",
        "    results = torch.load(file_path)\n",
        "    point_ids = [result.get(\"point_id\") for result in results if \"point_id\" in result]\n",
        "    point_ids_lists.append(point_ids)\n",
        "\n",
        "# Check if the order of point_ids is the same for all files\n",
        "same_order = all(point_ids == point_ids_lists[0] for point_ids in point_ids_lists)\n",
        "\n",
        "if same_order:\n",
        "    print(\"The order of point_ids is the same for all files.\")\n",
        "else:\n",
        "    print(\"The order of point_ids is different for one or more files.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWziRxH9hSH3",
        "outputId": "3d21c8cc-adda-4b18-a12c-cfa681778215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-70-5e53d5cd218c>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  results = torch.load(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Item 1:\n",
            "lst_encoded: tensor([ 3.0010,  0.9062, -0.7289, -1.7117,  1.0321, -1.8240, -0.6961, -0.6529,\n",
            "        -1.0488,  0.5545], device='cuda:0', requires_grad=True)\n",
            "point_ids: tensor([28382290])\n",
            "OC: tensor([85.4000], dtype=torch.float64)\n",
            "\n",
            "\n",
            "Item 2:\n",
            "lst_encoded: tensor([ 3.5936, -0.5233, -2.0914, -0.1449,  0.5875, -0.7096,  0.4047,  1.2617,\n",
            "        -0.6076,  1.4135], device='cuda:0', requires_grad=True)\n",
            "point_ids: tensor([28542300])\n",
            "OC: tensor([14.7000], dtype=torch.float64)\n",
            "\n",
            "\n",
            "Item 3:\n",
            "lst_encoded: tensor([ 3.4565, -1.1784,  0.2880, -0.7027,  0.7897, -2.5051, -0.5620, -1.0091,\n",
            "        -0.0845,  0.6329], device='cuda:0', requires_grad=True)\n",
            "point_ids: tensor([27922352])\n",
            "OC: tensor([23.2000], dtype=torch.float64)\n",
            "\n",
            "\n",
            "Item 4:\n",
            "lst_encoded: tensor([ 3.3966,  0.2875, -1.0935,  1.2738, -0.3078, -0.7294,  0.8841,  0.3546,\n",
            "        -0.7162,  1.1394], device='cuda:0', requires_grad=True)\n",
            "point_ids: tensor([27942398])\n",
            "OC: tensor([89.4000], dtype=torch.float64)\n",
            "\n",
            "\n",
            "Item 5:\n",
            "lst_encoded: tensor([ 3.3873,  0.2180,  0.4263,  0.8154, -0.0859, -1.1566, -0.1580, -0.0383,\n",
            "        -0.5226,  1.8162], device='cuda:0', requires_grad=True)\n",
            "point_ids: tensor([28002400])\n",
            "OC: tensor([55.3000], dtype=torch.float64)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define the file path\n",
        "file_path = '/content/epoch_vae_lst_results.pt'\n",
        "\n",
        "# Load the file using torch.load\n",
        "results = torch.load(file_path)\n",
        "\n",
        "# Assuming the file contains a list of dictionaries\n",
        "# Print the first 5 items (rows)\n",
        "for i, result in enumerate(results[:5]):\n",
        "    print(f\"Item {i + 1}:\")\n",
        "    for key, value in result.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prDLEbqYabwO",
        "outputId": "a749ab2a-0b1a-4e66-9064-170b163c97cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-71-e8627c330ddd>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  results = torch.load(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Item 1:\n",
            "npp_encoded: torch.Size([1, 40, 1, 1])\n",
            "point_ids: torch.Size([1])\n",
            "OC: torch.Size([1])\n",
            "\n",
            "\n",
            "Item 2:\n",
            "npp_encoded: torch.Size([1, 40, 1, 1])\n",
            "point_ids: torch.Size([1])\n",
            "OC: torch.Size([1])\n",
            "\n",
            "\n",
            "Item 3:\n",
            "npp_encoded: torch.Size([1, 40, 1, 1])\n",
            "point_ids: torch.Size([1])\n",
            "OC: torch.Size([1])\n",
            "\n",
            "\n",
            "Item 4:\n",
            "npp_encoded: torch.Size([1, 40, 1, 1])\n",
            "point_ids: torch.Size([1])\n",
            "OC: torch.Size([1])\n",
            "\n",
            "\n",
            "Item 5:\n",
            "npp_encoded: torch.Size([1, 40, 1, 1])\n",
            "point_ids: torch.Size([1])\n",
            "OC: torch.Size([1])\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-71-e8627c330ddd>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  results = torch.load(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Item 1:\n",
            "elevation_encoded: torch.Size([1, 40, 1, 1])\n",
            "point_ids: torch.Size([1])\n",
            "OC: torch.Size([1])\n",
            "\n",
            "\n",
            "Item 2:\n",
            "elevation_encoded: torch.Size([1, 40, 1, 1])\n",
            "point_ids: torch.Size([1])\n",
            "OC: torch.Size([1])\n",
            "\n",
            "\n",
            "Item 3:\n",
            "elevation_encoded: torch.Size([1, 40, 1, 1])\n",
            "point_ids: torch.Size([1])\n",
            "OC: torch.Size([1])\n",
            "\n",
            "\n",
            "Item 4:\n",
            "elevation_encoded: torch.Size([1, 40, 1, 1])\n",
            "point_ids: torch.Size([1])\n",
            "OC: torch.Size([1])\n",
            "\n",
            "\n",
            "Item 5:\n",
            "elevation_encoded: torch.Size([1, 40, 1, 1])\n",
            "point_ids: torch.Size([1])\n",
            "OC: torch.Size([1])\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define the file path\n",
        "file_path = '/content/epoch_vae_npp_results.pt'\n",
        "\n",
        "# Load the file using torch.load\n",
        "results = torch.load(file_path)\n",
        "\n",
        "# Assuming the file contains a list of dictionaries\n",
        "# Print the first 5 items (rows)\n",
        "for i, result in enumerate(results[:5]):\n",
        "    print(f\"Item {i + 1}:\")\n",
        "    for key, value in result.items():\n",
        "        print(f\"{key}: {value.shape}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Define the file path\n",
        "file_path = '/content/epoch_vae_elevation_results.pt'\n",
        "\n",
        "# Load the file using torch.load\n",
        "results = torch.load(file_path)\n",
        "\n",
        "# Assuming the file contains a list of dictionaries\n",
        "# Print the first 5 items (rows)\n",
        "for i, result in enumerate(results[:5]):\n",
        "    print(f\"Item {i + 1}:\")\n",
        "    for key, value in result.items():\n",
        "        print(f\"{key}: {value.shape}\")\n",
        "    print(\"\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "HAmCvRGRJOfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c73ff7-1fa4-4211-8e66-ad78d2707b97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Destination path '/content/drive/MyDrive/MLTRANS/FilteredLucas/epoch_vae_elevation_results.pt' already exists\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "source_file_path = '/content/epoch_vae_elevation_results.pt'\n",
        "# Define the destination folder path\n",
        "destination_folder = '/content/drive/MyDrive/MLTRANS/FilteredLucas/'\n",
        "\n",
        "# Use shutil to move the file\n",
        "try:\n",
        "    shutil.move(source_file_path, destination_folder)\n",
        "    print(f\"File moved successfully to {destination_folder}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "rIH2fuukx_lj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Onzz799NyKTz"
      },
      "source": [
        "# Using a MLP to regress on the y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Do7Nfgg6yNMO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "7c5cd93c-5e44-4817-efc7-d35e9a30524f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-29fca45b0639>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mXtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mytensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ],
      "source": [
        "Xtensor = torch.tensor(X, dtype=torch.float32)\n",
        "ytensor = torch.tensor(y, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-ZodnraygMf"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(Xtensor.shape[0], 10),  # Input layer with 20 features and first hidden layer with 50 neurons\n",
        "            nn.ReLU(),          # Activation function\n",
        "            nn.Linear(10, 10),  # Second hidden layer with 20 neurons\n",
        "            nn.ReLU(),          # Activation function\n",
        "            nn.Linear(10, 1),   # Output layer with 1 output for binary classification\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5WzsVkDyp5P"
      },
      "outputs": [],
      "source": [
        "model = SimpleMLP()\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):  # number of epochs\n",
        "    optimizer.zero_grad()  # clear gradients\n",
        "    outputs = model(X)     # forward pass\n",
        "    loss = criterion(outputs.squeeze(), y)  # calculate loss\n",
        "    loss.backward()        # backward pass (compute gradients)\n",
        "    optimizer.step()       # update weights\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/100], Loss: {loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kntqbA5lyxN6"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():  # inference mode\n",
        "    outputs = model(X)\n",
        "    predicted = outputs.round()  # for binary classification\n",
        "    accuracy = (predicted.squeeze() == y).float().mean()\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}